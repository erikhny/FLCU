{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6af8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1e36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13b9e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923 5923 980 980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_data_labels, test_data, test_data_labels = [[[] for i in range(10)] for i in range(4)]\n",
    "\n",
    "def sort_lists(list_a, list_b, data_entry, data_label):\n",
    "    list_a[data_label].append(data_entry)\n",
    "    list_b[data_label].append(data_label)\n",
    "    \n",
    "list(map(lambda a,b:sort_lists(train_data,train_data_labels, a, b), train_images, train_labels))\n",
    "list(map(lambda a,b:sort_lists(test_data,test_data_labels, a, b), test_images, test_labels))\n",
    "\n",
    "train_data, train_data_labels, test_data_labels, test_data_labels = np.asarray(train_data), np.asarray(train_data_labels), np.asarray(test_data_labels), np.asarray(test_data_labels)\n",
    "print(len(train_data[0]), len(train_data_labels[0]), len(test_data[0]), len(test_data_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0fb063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self):\n",
    "        self.clients = []\n",
    "        self.client_weights = []\n",
    "        self.weights = []\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        self.model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(0.1),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "        \n",
    "    def train_clients(self):\n",
    "        for c in self.clients:\n",
    "            self.client_weights.append(c.train())\n",
    "        return self.client_weights\n",
    "    \n",
    "    def update_weights(self, new_weights):\n",
    "        self.weights = new_weights\n",
    "        for c in self.clients:\n",
    "            self.clients.update_weights(self.get_weights())\n",
    "            \n",
    "    def federated_averaging(self, rnds):\n",
    "        average_weights = np.asarray(self.model.get_weights())\n",
    "        # Training for a specified amount of rounds\n",
    "        for rnd in range(rnds):\n",
    "            t_weights = []\n",
    "            total_samples = 0\n",
    "            # Training loop - trains each client for a single round for a specified amount of epochs\n",
    "            for client in self.clients:\n",
    "                t_weights.append(client.train())\n",
    "\n",
    "                total_samples += client.get_sample_amount()\n",
    "\n",
    "            tmp_weights = [t_weights[i] * len(self.clients[i].dataset.testing_data) for i in range(len(self.clients))]\n",
    "            tmp_weights = [w / total_samples for w in average_weights]\n",
    "\n",
    "            average_weights = [x + y for x, y in zip(init_weights, tmp_weights)]\n",
    "\n",
    "        self.model.set_weights(average_weights)\n",
    "        print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583c941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing the client and the necessary methods a client requires.\n",
    "class Client():\n",
    "    def __init__(self, dataset):\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        self.model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )\n",
    "        self.dataset = dataset\n",
    "        self.active_weights = self.get_weights()\n",
    "        self.rep_weights = self.active_weights\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    # Getter just for better readability\n",
    "    def get_sample_amount(self):\n",
    "        return len(self.dataset.training_data)\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.fit(\n",
    "                self.dataset.training_data, \n",
    "                self.dataset.training_labels, \n",
    "                epochs=LOCAL_EPOCHS, \n",
    "                validation_data=(\n",
    "                    self.dataset.testing_data,\n",
    "                    self.dataset.testing_labels\n",
    "                ))\n",
    "        \n",
    "        self.rep_weights = np.asarray(self.model.get_weights())\n",
    "        return self.rep_weights\n",
    "    \n",
    "    def update_weights(self, new_weights):\n",
    "        assert self.active_weights.shape == new_weights.shape, \"Shapes for the input weights are not the same\"\n",
    "        self.active_weights = np.mean( np.array([ self.active_weights, new_weights ]), axis=0 )\n",
    "        self.model.set_weights(self.active_weights)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88abb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, training_data, training_labels, testing_data, testing_labels):\n",
    "        self.training_data = np.asarray(training_data)\n",
    "        self.training_labels = np.asarray(training_labels)\n",
    "        self.testing_data = np.asarray(testing_data)\n",
    "        self.testing_labels = np.asarray(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc434531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb789756",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLIENTS = 10 # Currently only 10 data splits\n",
    "LOCAL_EPOCHS = 3\n",
    "ROUNDS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6301411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "init_weights = np.asarray(server.model.get_weights())\n",
    "#[i * 0 for i in model.get_weights()]\n",
    "\n",
    "server.clients = [Client(Dataset(train_data[i], train_data_labels[i], test_data[i], test_data_labels[i])) for i in range(NUMBER_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6647fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_client_weights(weights, clients):\n",
    "    for c in clients:\n",
    "        c.model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adc0cb78",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Server' object has no attribute 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15524/1493316789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FINISHED'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfederated_averaging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROUNDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15524/408538135.py\u001b[0m in \u001b[0;36mfederated_averaging\u001b[1;34m(self, rnds)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# Training loop - trains each client for a single round for a specified amount of epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mt_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mtotal_samples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sample_amount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Server' object has no attribute 'client'"
     ]
    }
   ],
   "source": [
    "set_client_weights(init_weights, server.clients)\n",
    "#model.set_weights(init_weights)\n",
    "def FedAvg():\n",
    "    weights = []\n",
    "    average_weights = np.asarray(model.get_weights())\n",
    "    # Training for a specified amount of rounds\n",
    "    for rnd in range(ROUNDS):\n",
    "        t_weights = []\n",
    "        total_samples = 0\n",
    "        # Training loop - trains each client for a single round for a specified amount of epochs\n",
    "        for client in clients:\n",
    "            t_weights.append(client.train())\n",
    "            \n",
    "            total_samples += client.get_sample_amount()\n",
    "            \n",
    "        tmp_weights = [t_weights[i] * len(clients[i].dataset.testing_data) for i in range(NUMBER_OF_CLIENTS)]\n",
    "        tmp_weights = [w / total_samples for w in average_weights]\n",
    "        \n",
    "        average_weights = [x + y for x, y in zip(init_weights, tmp_weights)]\n",
    "        \n",
    "    model.set_weights(average_weights)\n",
    "    print('FINISHED')\n",
    "    \n",
    "server.federated_averaging(ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a03dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = []\n",
    "avgs = init_weights\n",
    "for c in clients:\n",
    "    avgs += c.model.get_weights()\n",
    "len(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedCD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "453dffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.9521 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    np.asarray(clients[0].dataset.training_data), \n",
    "    np.asarray(clients[0].dataset.training_labels), \n",
    "    epochs=10, \n",
    "    validation_data=(\n",
    "        np.asarray(clients[0].dataset.testing_data), \n",
    "        np.asarray(clients[0].dataset.testing_labels)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b154f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['sparse_categorical_accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(np.asarray(orderedListDataTest[0]),  np.asarray(orderedListLabelsTest[0]), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MODELS = 10\n",
    "models = []\n",
    "for i in range(NUMBER_OF_MODELS):\n",
    "    \n",
    "    models.append(\n",
    "        Client(model.fit(\n",
    "            np.asarray(orderedListData[i]), \n",
    "            np.asarray(orderedListLabels[i]), \n",
    "            epochs=10, \n",
    "            validation_data=(\n",
    "                np.asarray(orderedListDataTest[i]), np.asarray(orderedListLabelsTest[i])\n",
    "            )), len(orderedListData[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(models[0].model.get_weights() == models[1].model.get_weights()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(models[0].model.get_weights(), models[1].model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].sample_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bd4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2aa2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[] for i in range(10)]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9449f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_data[train_labels[i]].append(train_images[i]) for i in range(len(train_images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a146c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c4984cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = np.asarray(init_weights) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a3fe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32),\n",
       "       array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "      dtype=float32),\n",
       "       array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32),\n",
       "       array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_weights + np.asarray(init_weights)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55e3b299",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9184/892611796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32ma:\\projects\\python sesong 2\\env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1905\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIn\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprovided\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m     \"\"\"\n\u001b[1;32m-> 1907\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1908\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_on_batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_on_batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32ma:\\projects\\python sesong 2\\env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2788\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2789\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2790\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2791\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.test_on_batch(np.asarray(test_data[0]), test_data_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f085e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[-5.6002971e-02,  2.1686140e-02, -9.6797543e-03, ...,\n",
       "        -4.7229979e-02, -7.6520145e-02, -1.2377573e-02],\n",
       "       [ 1.2112358e-02, -3.8674895e-03, -3.5257181e-03, ...,\n",
       "        -4.1521162e-02,  8.1985323e-03, -7.4953407e-02],\n",
       "       [ 5.7165534e-03,  3.7762683e-02,  8.0781236e-02, ...,\n",
       "        -2.6858792e-02, -7.9602063e-02, -3.1655363e-03],\n",
       "       ...,\n",
       "       [ 7.4041031e-02, -1.4477338e-02, -4.4884910e-03, ...,\n",
       "        -5.8010451e-02,  3.8297068e-02, -7.5673158e-03],\n",
       "       [ 3.9834313e-02,  5.8950432e-02,  2.5539318e-02, ...,\n",
       "        -1.2250918e-02,  5.5434488e-02,  7.6218791e-02],\n",
       "       [ 4.1671792e-05, -2.1654811e-02,  2.1863624e-02, ...,\n",
       "        -1.4661824e-02,  8.1097126e-02,  1.5626416e-02]], dtype=float32),\n",
       "       array([-6.3707186e-03,  7.2517698e-03, -7.2182016e-03,  7.4329074e-03,\n",
       "        6.5392707e-03,  8.3692670e-03,  3.5246273e-03, -9.3602771e-03,\n",
       "        5.9933555e-03, -6.0041500e-03, -6.5946481e-03,  7.8022913e-03,\n",
       "       -3.1731666e-12,  5.3653501e-05, -5.8354586e-03,  5.7631922e-03,\n",
       "        6.2045469e-03,  8.5926801e-04, -6.6674985e-03,  7.3943064e-03,\n",
       "        5.1096622e-03, -6.9338474e-03, -8.1842579e-03,  8.4091658e-03,\n",
       "       -5.4064463e-03,  0.0000000e+00, -9.1024637e-03,  5.7140104e-03,\n",
       "        1.0555656e-23,  7.2890511e-03, -7.4776271e-03, -6.0014245e-03,\n",
       "        6.0101324e-03,  6.0030748e-03,  6.5092342e-03, -7.4732709e-03,\n",
       "        6.7688627e-03,  8.3845127e-03,  7.1743298e-03, -2.0623966e-03,\n",
       "       -6.0036411e-03,  5.9835301e-03, -7.2367275e-03,  7.4477326e-03,\n",
       "       -7.0912289e-03,  6.6929949e-03,  0.0000000e+00,  6.9666468e-03,\n",
       "       -5.9892731e-03, -5.8069653e-03, -7.3956167e-03, -6.0034203e-03,\n",
       "        7.1769720e-03, -6.9138804e-03, -6.7113028e-03, -7.1520698e-03,\n",
       "       -6.8731857e-03, -7.4577197e-03,  7.1730213e-03, -7.2092172e-03,\n",
       "        5.3360667e-03,  6.0114199e-03, -7.3180846e-03,  7.2292462e-03,\n",
       "       -8.1420327e-03, -6.0047698e-03, -6.0045728e-03,  0.0000000e+00,\n",
       "       -5.8648353e-03, -6.5735141e-03, -6.6650095e-03, -8.2872966e-03,\n",
       "       -5.0703618e-03,  6.7963558e-03, -8.0624241e-03, -6.3169021e-03,\n",
       "        7.3781917e-03,  7.8364033e-03, -7.2882604e-03,  5.5486048e-03,\n",
       "        6.5218341e-03, -6.8677883e-03,  7.1010212e-03,  6.4251623e-03,\n",
       "        6.4807669e-03, -7.9526333e-03, -5.9878929e-03, -7.0561459e-03,\n",
       "       -6.6213012e-03, -6.2639397e-03,  8.8186562e-03,  3.6985774e-03,\n",
       "        7.0952019e-03,  6.6169007e-03, -6.6286521e-03, -5.9961206e-03,\n",
       "       -6.3981963e-03, -6.6041206e-03,  6.3189873e-03,  1.0587545e-03,\n",
       "       -7.6597640e-03, -5.9876465e-03,  7.1273521e-03,  7.9567824e-03,\n",
       "       -6.4614415e-03, -7.3992093e-03, -7.1115894e-03,  6.1450973e-03,\n",
       "        7.7437465e-03,  8.1052324e-03, -6.1105783e-03, -7.2692079e-03,\n",
       "       -8.0940276e-03, -7.5318073e-03, -8.4366631e-03,  6.6386028e-03,\n",
       "        7.2843321e-03, -7.6641021e-03,  7.5333561e-03, -5.9966459e-03,\n",
       "       -7.5243036e-03, -6.8588573e-03,  8.4259072e-03, -8.3054425e-03,\n",
       "       -5.8441572e-03,  6.0544508e-03,  7.4875406e-03,  6.4841183e-03],\n",
       "      dtype=float32),\n",
       "       array([[-0.07205292,  0.17346834,  0.18925957, ..., -0.09134654,\n",
       "         0.1388497 , -0.0625393 ],\n",
       "       [ 0.12340648, -0.17911771,  0.02392244, ..., -0.19376494,\n",
       "        -0.1200456 ,  0.09932284],\n",
       "       [-0.1483438 ,  0.12104296, -0.02959387, ..., -0.20993415,\n",
       "         0.17454188,  0.02350026],\n",
       "       ...,\n",
       "       [ 0.0711071 , -0.01714251, -0.19552022, ..., -0.11652634,\n",
       "        -0.07142162, -0.06337386],\n",
       "       [ 0.19719808,  0.09616207,  0.08883918, ..., -0.12249904,\n",
       "         0.12681217, -0.02238998],\n",
       "       [ 0.04055465, -0.05608134, -0.09003914, ...,  0.13022402,\n",
       "        -0.1456165 , -0.03834472]], dtype=float32),\n",
       "       array([ 6.9672768e-03, -6.0053496e-03, -3.1003310e-24, -6.0113906e-03,\n",
       "       -6.0054539e-03,  0.0000000e+00, -7.8126639e-03, -6.0052481e-03,\n",
       "       -6.0049403e-03, -7.3003629e-03], dtype=float32)], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d5cec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "        150, 253, 202,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 190, 251,\n",
       "        251, 251, 253, 169, 109,  62,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251,\n",
       "        251, 251, 253, 251, 251, 220,  51,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 255, 253, 253,\n",
       "        253, 253, 234, 222, 253, 253, 253,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 221, 253, 251, 251,\n",
       "        251, 147,  77,  62, 128, 251, 251, 105,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 231, 251, 253, 251, 220,\n",
       "        137,  10,   0,   0,  31, 230, 251, 243, 113,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 188,  20,\n",
       "          0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 201,  30,   0,\n",
       "          0,   0,   0,   0,   0,  31, 200, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 253, 253,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  32, 202, 255, 253, 164,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0,  21,  63, 231, 251, 253, 230,  30,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0, 144, 251, 251, 251, 221,  61,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0, 182, 221, 251, 251, 251, 180,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 218, 253, 253,  73,  73, 228,\n",
       "        253, 253, 255, 253, 253, 253, 253,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 113, 251, 251, 253, 251, 251,\n",
       "        251, 251, 253, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  31, 230, 251, 253, 251, 251,\n",
       "        251, 251, 253, 230, 189,  35,  10,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  62, 142, 253, 251, 251,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 174, 251,\n",
       "        173,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d7f0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
