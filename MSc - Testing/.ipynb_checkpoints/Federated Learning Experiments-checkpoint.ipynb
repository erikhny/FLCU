{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd00a72",
   "metadata": {},
   "source": [
    "# Federated learning - Client aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48529658",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6af8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205ae09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "NUMBER_OF_CLIENTS = 10\n",
    "MNIST_CLASS_AMOUNT = 10\n",
    "MNIST_SHAPE = (28,28)\n",
    "CIFAR_CLASS_AMOUNT = 10\n",
    "LOCAL_EPOCHS = 1\n",
    "ROUNDS = 100\n",
    "LOCAL_LR = 0.01\n",
    "GLOBAL_LR = 0.1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(LOCAL_LR, decay=LOCAL_LR/ROUNDS, momentum=0.9)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "model_metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "\n",
    "## FT CONSTANTS\n",
    "FT_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d9ba7",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b95fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lists(list_a, list_b, data_entry, data_label):\n",
    "    list_a[data_label].append(data_entry)\n",
    "    list_b[data_label].append(data_label)\n",
    "    \n",
    "def sort_lists_cifar(list_a, list_b, data_entry, data_label):\n",
    "    list_a[data_label[0]].append(data_entry)\n",
    "    list_b[data_label[0]].append(data_label[0])\n",
    "    \n",
    "def split(array, partitions):\n",
    "    k, m = divmod(len(array), partitions)\n",
    "    return (array[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(partitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8b072",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f502ac",
   "metadata": {},
   "source": [
    "##### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13b9e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6139"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "ordered_train_data, ordered_train_data_labels, ordered_test_data, ordered_test_data_labels = [[[] for i in range(10)] for i in range(4)]\n",
    "    \n",
    "list(map(lambda a,b:sort_lists(ordered_train_data,ordered_train_data_labels, a, b), train_images, train_labels))\n",
    "list(map(lambda a,b:sort_lists(ordered_test_data,ordered_test_data_labels, a, b), test_images, test_labels))\n",
    "t = [4, 1, 4, 1, 3, 2, 2, 3, 4, 3]\n",
    "#t = []\n",
    "for i in range(len(ordered_train_data)):\n",
    "    #t.append(random.randrange(1, 5))\n",
    "    ordered_train_data[i] = list(split(ordered_train_data[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    ordered_train_data_labels[i] = list(split(ordered_train_data_labels[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    ordered_test_data[i] = list(split(ordered_test_data[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    ordered_test_data_labels[i] = list(split(ordered_test_data_labels[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    \n",
    "train_data, train_data_labels, test_data, test_data_labels = [[[] for i in range(NUMBER_OF_CLIENTS)] for i in range(4)]\n",
    "        \n",
    "for i in range(NUMBER_OF_CLIENTS):\n",
    "    for j in range(MNIST_CLASS_AMOUNT):\n",
    "        if i == j:\n",
    "            train_data[i] += ordered_train_data[j][i]\n",
    "            train_data_labels[i] += ordered_train_data_labels[j][i] \n",
    "            test_data[i] += ordered_test_data[j][i]\n",
    "            test_data_labels[i] += ordered_test_data_labels[j][i]\n",
    "            for e in range(t[i]):\n",
    "                train_data[i] += ordered_train_data[j][10+e]\n",
    "                train_data_labels[i] += ordered_train_data_labels[j][10+e] \n",
    "                test_data[i] += ordered_test_data[j][10+e]\n",
    "                test_data_labels[i] += ordered_test_data_labels[j][10+e]\n",
    "        else:\n",
    "            train_data[i] += ordered_train_data[j][i]\n",
    "            train_data_labels[i] += ordered_train_data_labels[j][i]\n",
    "            test_data[i] += ordered_test_data[j][i]\n",
    "            test_data_labels[i] += ordered_test_data_labels[j][i]\n",
    "len(train_data_labels[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0422b37",
   "metadata": {},
   "source": [
    "###### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f867cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cifar_images, cifar_labels), (cifar_test_images, cifar_test_labels) = datasets.cifar10.load_data()\n",
    "ordered_cifar_train_data, ordered_cifar_train_labels, ordered_cifar_test_data, ordered_cifar_test_labels = [[[] for i in range(10)] for i in range(4)]\n",
    "\n",
    "list(map(lambda a,b:sort_lists_cifar(ordered_cifar_train_data,ordered_cifar_train_labels, a, b), cifar_images, cifar_labels))\n",
    "list(map(lambda a,b:sort_lists_cifar(ordered_cifar_test_data,ordered_cifar_test_labels, a, b), cifar_test_images, cifar_test_labels))\n",
    "\n",
    "t = [3, 3, 3, 1, 2, 2, 2, 3, 4, 1]\n",
    "for i in range(len(ordered_cifar_train_data)):\n",
    "    #t.append(random.randrange(1, 5))\n",
    "    ordered_cifar_train_data[i] = list(split(ordered_cifar_train_data[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    ordered_cifar_train_labels[i] = list(split(ordered_cifar_train_labels[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    ordered_cifar_test_data[i] = list(split(ordered_cifar_test_data[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    ordered_cifar_test_labels[i] = list(split(ordered_cifar_test_labels[i], NUMBER_OF_CLIENTS+t[i]))\n",
    "    \n",
    "cifar_train_data, cifar_train_data_labels, cifar_test_data, cifar_test_data_labels = [[[] for i in range(NUMBER_OF_CLIENTS)] for i in range(4)]\n",
    "\n",
    "for i in range(NUMBER_OF_CLIENTS):\n",
    "    for j in range(MNIST_CLASS_AMOUNT):\n",
    "        if i == j:\n",
    "            cifar_train_data[i] += ordered_cifar_train_data[j][i]\n",
    "            cifar_train_data_labels[i] += ordered_cifar_train_labels[j][i] \n",
    "            cifar_test_data[i] += ordered_cifar_test_data[j][i]\n",
    "            cifar_test_data_labels[i] += ordered_cifar_test_labels[j][i]\n",
    "            for e in range(t[i]):\n",
    "                cifar_train_data[i] += ordered_cifar_train_data[j][10+e]\n",
    "                cifar_train_data_labels[i] += ordered_cifar_train_labels[j][10+e] \n",
    "                cifar_test_data[i] += ordered_cifar_test_data[j][10+e]\n",
    "                cifar_test_data_labels[i] += ordered_cifar_test_labels[j][10+e]\n",
    "        else:\n",
    "            cifar_train_data[i] += ordered_cifar_train_data[j][i]\n",
    "            cifar_train_data_labels[i] += ordered_cifar_train_labels[j][i]\n",
    "            cifar_test_data[i] += ordered_cifar_test_data[j][i]\n",
    "            cifar_test_data_labels[i] += ordered_cifar_test_labels[j][i]\n",
    "cifar_train_data_labels[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1616c",
   "metadata": {},
   "source": [
    "### Classes and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d227a6",
   "metadata": {},
   "source": [
    "###### Server class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e86f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self):\n",
    "        self.clients = []\n",
    "        self.client_weights = []\n",
    "        self.weights = []\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.Dense(MNIST_CLASS_AMOUNT, activation='softmax')\n",
    "        ])\n",
    "        self.model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=model_metrics,\n",
    "             )\n",
    "        self.total_samples = self.get_total_samples()\n",
    "        self.results = [[], []]\n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    def get_total_samples(self):\n",
    "        ts = 0\n",
    "        for c in self.clients:\n",
    "            ts += c.get_sample_amount()\n",
    "        return ts\n",
    "    \n",
    "    # Performs a single round of training for set amount of epochs    \n",
    "    def train_clients(self):\n",
    "        for c in self.clients:\n",
    "            self.client_weights.append(c.train())\n",
    "        return self.client_weights\n",
    "    \n",
    "    # Updates weights for server and clients\n",
    "    def update_weights(self, new_weights):\n",
    "        for c in self.clients:\n",
    "            c.update_weights(new_weights)\n",
    "            c.ensemble()\n",
    "            c.global_sample_amount = self.total_samples\n",
    "            c.average_models()\n",
    "            \n",
    "    # Performs federated averaging for given amount of rounds\n",
    "    def federated_averaging(self):\n",
    "        self.total_samples = self.get_total_samples()\n",
    "        # Training for a specified amount of rounds\n",
    "        for rnd in range(ROUNDS):\n",
    "            print(\"-------------------------------ROUND \" + str(rnd+1) + \"-------------------------------\")\n",
    "            average_weights = []\n",
    "            t_weights = []\n",
    "            # Training loop - trains each client for a single round for a specified amount of epochs\n",
    "            for client in self.clients:\n",
    "                \n",
    "                client_weights = client.train(LOCAL_EPOCHS)\n",
    "                \n",
    "                s = client.get_sample_amount() / self.total_samples\n",
    "                temp = []\n",
    "                for w in client_weights:\n",
    "                    l = w * s\n",
    "                    temp.append(l)\n",
    "                #t_weights.append(np.asarray(client_weights) * s)\n",
    "                t_weights.append(temp)\n",
    "                \n",
    "            for e in zip(*t_weights):\n",
    "                average_weights.append(tf.math.reduce_sum(e, axis=0))\n",
    "                #average_weights.append()\n",
    "            \n",
    "            #tmp_weights = [t_weights[i] * len(self.clients[i].dataset.training_data) for i in range(len(self.clients))]\n",
    "            #tmp_weights = [w / total_samples for w in average_weights]\n",
    "\n",
    "            #average_weights = [x + y for x, y in zip(init_weights, tmp_weights)]\n",
    "            print(len(average_weights), len(self.weights))\n",
    "            self.weights = average_weights\n",
    "            self.update_weights(average_weights)\n",
    "            self.eval_model()\n",
    "            \n",
    "        print('FINISHED')\n",
    "        \n",
    "    def eval_model(self):\n",
    "        self.model.set_weights(self.weights)\n",
    "        eval_loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        preds = self.model.predict(test_images.reshape(-1, 28, 28, 1))\n",
    "        eval_loss = eval_loss_func(test_labels, preds)\n",
    "        accuracy = metrics.accuracy_score(test_labels, tf.argmax(preds, axis=1))\n",
    "        print('global acc: {} ----- loss: {}'.format(accuracy, eval_loss))\n",
    "        self.results[0].append(accuracy)\n",
    "        self.results[1].append(eval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e491687",
   "metadata": {},
   "source": [
    "###### Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583c941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing the client and the necessary methods a client requires.\n",
    "class Client():\n",
    "    def __init__(self, dataset, init_weights):\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.Dense(MNIST_CLASS_AMOUNT, activation='softmax')\n",
    "        ])\n",
    "        self.dataset = dataset\n",
    "        self.local_weights = self.get_weights()\n",
    "        self.global_weights = init_weights\n",
    "        self.global_sample_amount = 0\n",
    "        self.ensemble_results = [[], []]\n",
    "        self.averaged_results= [[], []]\n",
    "        self.global_results = [[], []]\n",
    "        self.local_results = [[], []]\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    # Getter just for better readability\n",
    "    def get_sample_amount(self):\n",
    "        return len(self.dataset.training_data)\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        self.model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=model_metrics,\n",
    "             )\n",
    "        self.model.set_weights(self.global_weights)\n",
    "        self.model.fit(\n",
    "                self.dataset.training_data, \n",
    "                self.dataset.training_labels, \n",
    "                epochs=LOCAL_EPOCHS, \n",
    "                validation_data=(\n",
    "                    self.dataset.testing_data,\n",
    "                    self.dataset.testing_labels\n",
    "                ), batch_size=BATCH_SIZE, verbose=0)\n",
    "        \n",
    "        self.local_weights = self.model.get_weights()\n",
    "        glob_res = self.calculate_metrics(self.global_pred())\n",
    "        loc_res = self.calculate_metrics(self.local_pred())\n",
    "        self.global_results[0].append(glob_res[0])\n",
    "        self.global_results[1].append(glob_res[1])\n",
    "        self.local_results[0].append(loc_res[0])\n",
    "        self.local_results[1].append(loc_res[1])\n",
    "        tf.keras.backend.clear_session()\n",
    "        return self.local_weights\n",
    "    \n",
    "    def update_weights(self, new_weights):\n",
    "        self.global_weights = new_weights\n",
    "        \n",
    "    \n",
    "    def ensemble(self):\n",
    "        local_preds = self.local_pred()\n",
    "        global_preds = self.global_pred()\n",
    "        combined_preds = []\n",
    "        #local_preds.append(self.local_pred(d))\n",
    "        #global_preds.append(self.global_pred(d))\n",
    "        \n",
    "        local_dict = metrics.classification_report(self.dataset.testing_labels, [np.argmax(p) for p in local_preds], output_dict=True)\n",
    "        global_dict = metrics.classification_report(self.dataset.testing_labels, [np.argmax(p) for p in global_preds], output_dict=True)\n",
    "        \n",
    "        for i in range(len(local_preds)):\n",
    "            if np.argmax(local_preds[i]) == np.argmax(global_preds[i]):\n",
    "                combined_preds.append(local_preds[i])\n",
    "            elif local_dict[str(np.argmax(local_preds[i]))]['f1-score'] > global_dict[str(np.argmax(global_preds[i]))]['f1-score']:\n",
    "                combined_preds.append(local_preds[i])\n",
    "            else:\n",
    "                combined_preds.append(global_preds[i])\n",
    "            \n",
    "        #self.ensemble_results.append(metrics.classification_report(self.dataset.testing_labels, combined_preds, output_dict=True, digits=4))\n",
    "        res = self.calculate_metrics(combined_preds)\n",
    "        self.ensemble_results[0].append(res[0])\n",
    "        self.ensemble_results[1].append(res[1])\n",
    "            \n",
    "    def average_models(self):\n",
    "        size = len(self.local_weights)\n",
    "        avg_weights = []\n",
    "        local_scaling_factor = self.get_sample_amount() / self.global_sample_amount\n",
    "        global_scaling_factor = 1 - local_scaling_factor\n",
    "        for i in range(size):\n",
    "            avg_weights.append(self.local_weights[i] * local_scaling_factor + self.global_weights[i] * global_scaling_factor)\n",
    "        #avg_weights = self.local_weights * local_acc + self.global_weights * global_acc\n",
    "        \n",
    "        self.model.set_weights(avg_weights)\n",
    "        prediction = self.model(self.dataset.testing_data, training=False)\n",
    "        res = self.calculate_metrics(prediction)\n",
    "        self.averaged_results[0].append(res[0])\n",
    "        self.averaged_results[1].append(res[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Returns the label with highest accuracy using the local weights\n",
    "    def local_pred(self):\n",
    "        self.model.set_weights(self.local_weights)\n",
    "        prediction = self.model(self.dataset.testing_data, training=False)\n",
    "        #remove argmax\n",
    "        return prediction\n",
    "    \n",
    "    # Returns the label with highest accuracy using the global weights\n",
    "    def global_pred(self):\n",
    "        self.model.set_weights(self.global_weights)\n",
    "        prediction = self.model(self.dataset.testing_data, training=False)\n",
    "        #remove argmax\n",
    "        return prediction\n",
    "    \n",
    "    def calculate_metrics(self, preds):\n",
    "        eval_loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        eval_loss = eval_loss_func(self.dataset.testing_labels, preds)\n",
    "        accuracy = metrics.accuracy_score(self.dataset.testing_labels, tf.argmax(preds, axis=1))\n",
    "        return [accuracy, eval_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd18474",
   "metadata": {},
   "source": [
    "###### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88abb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, training_data, training_labels, testing_data, testing_labels):\n",
    "        self.training_data = np.asarray(training_data).reshape(-1, 28, 28, 1)\n",
    "        self.training_labels = np.asarray(training_labels)\n",
    "        self.testing_data = np.asarray(testing_data).reshape(-1, 28, 28, 1)\n",
    "        self.testing_labels = np.asarray(testing_labels)\n",
    "        \n",
    "    def get_training_data_distribution(self):\n",
    "        labels = np.unique(self.training_labels)\n",
    "        dist = {}\n",
    "        for i in labels:\n",
    "            dist[i] = np.where(self.training_labels == i)\n",
    "        return dist\n",
    "    \n",
    "    def get_testing_data_distribution(self):\n",
    "        labels = np.unique(self.testing_labels)\n",
    "        dist = {}\n",
    "        for i in labels:\n",
    "            dist[i] = np.where(self.testing_labels == i)\n",
    "        return dist\n",
    "    \n",
    "    def order_test_into_labels(self):\n",
    "        data, labels = [], []\n",
    "        list(map(lambda a,b:sort_lists(data,labels, a, b), self.testing_data, self.testing_labels))\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5057221",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55a397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------ROUND 1-------------------------------\n",
      "12 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global acc: 0.1679 ----- loss: 2.3023762702941895\n",
      "-------------------------------ROUND 2-------------------------------\n",
      "12 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global acc: 0.1065 ----- loss: 2.290684461593628\n",
      "-------------------------------ROUND 3-------------------------------\n",
      "12 12\n",
      "global acc: 0.7457 ----- loss: 1.827602744102478\n",
      "-------------------------------ROUND 4-------------------------------\n",
      "12 12\n",
      "global acc: 0.8116 ----- loss: 1.7224252223968506\n",
      "-------------------------------ROUND 5-------------------------------\n",
      "12 12\n",
      "global acc: 0.8387 ----- loss: 1.6925910711288452\n",
      "-------------------------------ROUND 6-------------------------------\n",
      "12 12\n",
      "global acc: 0.8522 ----- loss: 1.6630244255065918\n",
      "-------------------------------ROUND 7-------------------------------\n",
      "12 12\n",
      "global acc: 0.8575 ----- loss: 1.6536619663238525\n",
      "-------------------------------ROUND 8-------------------------------\n",
      "12 12\n",
      "global acc: 0.8673 ----- loss: 1.6425886154174805\n",
      "-------------------------------ROUND 9-------------------------------\n",
      "12 12\n",
      "global acc: 0.8758 ----- loss: 1.633974552154541\n",
      "-------------------------------ROUND 10-------------------------------\n",
      "12 12\n",
      "global acc: 0.8796 ----- loss: 1.6305299997329712\n",
      "-------------------------------ROUND 11-------------------------------\n",
      "12 12\n",
      "global acc: 0.8818 ----- loss: 1.620544672012329\n",
      "-------------------------------ROUND 12-------------------------------\n",
      "12 12\n",
      "global acc: 0.8881 ----- loss: 1.6164859533309937\n",
      "-------------------------------ROUND 13-------------------------------\n",
      "12 12\n",
      "global acc: 0.8913 ----- loss: 1.6137409210205078\n",
      "-------------------------------ROUND 14-------------------------------\n",
      "12 12\n",
      "global acc: 0.8913 ----- loss: 1.6119450330734253\n",
      "-------------------------------ROUND 15-------------------------------\n",
      "12 12\n",
      "global acc: 0.8939 ----- loss: 1.6086606979370117\n",
      "-------------------------------ROUND 16-------------------------------\n",
      "12 12\n",
      "global acc: 0.8963 ----- loss: 1.6083214282989502\n",
      "-------------------------------ROUND 17-------------------------------\n",
      "12 12\n",
      "global acc: 0.8952 ----- loss: 1.6051217317581177\n",
      "-------------------------------ROUND 18-------------------------------\n",
      "12 12\n",
      "global acc: 0.8987 ----- loss: 1.6018887758255005\n",
      "-------------------------------ROUND 19-------------------------------\n",
      "12 12\n",
      "global acc: 0.8985 ----- loss: 1.59762704372406\n",
      "-------------------------------ROUND 20-------------------------------\n",
      "12 12\n",
      "global acc: 0.9008 ----- loss: 1.598172664642334\n",
      "-------------------------------ROUND 21-------------------------------\n",
      "12 12\n",
      "global acc: 0.9028 ----- loss: 1.5954829454421997\n",
      "-------------------------------ROUND 22-------------------------------\n",
      "12 12\n",
      "global acc: 0.903 ----- loss: 1.5954452753067017\n",
      "-------------------------------ROUND 23-------------------------------\n",
      "12 12\n",
      "global acc: 0.9056 ----- loss: 1.5943593978881836\n",
      "-------------------------------ROUND 24-------------------------------\n",
      "12 12\n",
      "global acc: 0.9058 ----- loss: 1.5918245315551758\n",
      "-------------------------------ROUND 25-------------------------------\n",
      "12 12\n",
      "global acc: 0.9072 ----- loss: 1.5903205871582031\n",
      "-------------------------------ROUND 26-------------------------------\n",
      "12 12\n",
      "global acc: 0.9065 ----- loss: 1.589473843574524\n",
      "-------------------------------ROUND 27-------------------------------\n",
      "12 12\n",
      "global acc: 0.9091 ----- loss: 1.5864263772964478\n",
      "-------------------------------ROUND 28-------------------------------\n",
      "12 12\n",
      "global acc: 0.9083 ----- loss: 1.5871587991714478\n",
      "-------------------------------ROUND 29-------------------------------\n",
      "12 12\n",
      "global acc: 0.9117 ----- loss: 1.5857677459716797\n",
      "-------------------------------ROUND 30-------------------------------\n",
      "12 12\n",
      "global acc: 0.9108 ----- loss: 1.583449125289917\n",
      "-------------------------------ROUND 31-------------------------------\n",
      "12 12\n",
      "global acc: 0.9104 ----- loss: 1.582585096359253\n",
      "-------------------------------ROUND 32-------------------------------\n",
      "12 12\n",
      "global acc: 0.9124 ----- loss: 1.5826507806777954\n",
      "-------------------------------ROUND 33-------------------------------\n",
      "12 12\n",
      "global acc: 0.9129 ----- loss: 1.582371711730957\n",
      "-------------------------------ROUND 34-------------------------------\n",
      "12 12\n",
      "global acc: 0.914 ----- loss: 1.582013487815857\n",
      "-------------------------------ROUND 35-------------------------------\n",
      "12 12\n",
      "global acc: 0.9135 ----- loss: 1.580048680305481\n",
      "-------------------------------ROUND 36-------------------------------\n",
      "12 12\n",
      "global acc: 0.9153 ----- loss: 1.5798444747924805\n",
      "-------------------------------ROUND 37-------------------------------\n",
      "12 12\n",
      "global acc: 0.9133 ----- loss: 1.5807057619094849\n",
      "-------------------------------ROUND 38-------------------------------\n",
      "12 12\n",
      "global acc: 0.9153 ----- loss: 1.578150987625122\n",
      "-------------------------------ROUND 39-------------------------------\n",
      "12 12\n",
      "global acc: 0.9159 ----- loss: 1.5773733854293823\n",
      "-------------------------------ROUND 40-------------------------------\n",
      "12 12\n",
      "global acc: 0.9156 ----- loss: 1.5777759552001953\n",
      "-------------------------------ROUND 41-------------------------------\n",
      "12 12\n",
      "global acc: 0.9171 ----- loss: 1.576617956161499\n",
      "-------------------------------ROUND 42-------------------------------\n",
      "12 12\n",
      "global acc: 0.9173 ----- loss: 1.5755304098129272\n",
      "-------------------------------ROUND 43-------------------------------\n",
      "12 12\n",
      "global acc: 0.9167 ----- loss: 1.5762097835540771\n",
      "-------------------------------ROUND 44-------------------------------\n",
      "12 12\n",
      "global acc: 0.9167 ----- loss: 1.575137734413147\n",
      "-------------------------------ROUND 45-------------------------------\n",
      "12 12\n",
      "global acc: 0.9181 ----- loss: 1.5747604370117188\n",
      "-------------------------------ROUND 46-------------------------------\n",
      "12 12\n",
      "global acc: 0.9184 ----- loss: 1.5742028951644897\n",
      "-------------------------------ROUND 47-------------------------------\n",
      "12 12\n",
      "global acc: 0.9178 ----- loss: 1.572654366493225\n",
      "-------------------------------ROUND 48-------------------------------\n",
      "12 12\n",
      "global acc: 0.9187 ----- loss: 1.572798728942871\n",
      "-------------------------------ROUND 49-------------------------------\n",
      "12 12\n",
      "global acc: 0.9184 ----- loss: 1.5719094276428223\n",
      "-------------------------------ROUND 50-------------------------------\n",
      "12 12\n",
      "global acc: 0.9195 ----- loss: 1.572333812713623\n",
      "-------------------------------ROUND 51-------------------------------\n",
      "12 12\n",
      "global acc: 0.9183 ----- loss: 1.5714141130447388\n",
      "-------------------------------ROUND 52-------------------------------\n",
      "12 12\n",
      "global acc: 0.9197 ----- loss: 1.5711569786071777\n",
      "-------------------------------ROUND 53-------------------------------\n",
      "12 12\n",
      "global acc: 0.918 ----- loss: 1.5700793266296387\n",
      "-------------------------------ROUND 54-------------------------------\n",
      "12 12\n",
      "global acc: 0.9194 ----- loss: 1.571471095085144\n",
      "-------------------------------ROUND 55-------------------------------\n",
      "12 12\n",
      "global acc: 0.919 ----- loss: 1.5695749521255493\n",
      "-------------------------------ROUND 56-------------------------------\n",
      "12 12\n",
      "global acc: 0.9197 ----- loss: 1.5685423612594604\n",
      "-------------------------------ROUND 57-------------------------------\n",
      "12 12\n",
      "global acc: 0.9198 ----- loss: 1.5699044466018677\n",
      "-------------------------------ROUND 58-------------------------------\n",
      "12 12\n",
      "global acc: 0.921 ----- loss: 1.5684422254562378\n",
      "-------------------------------ROUND 59-------------------------------\n",
      "12 12\n",
      "global acc: 0.92 ----- loss: 1.5686923265457153\n",
      "-------------------------------ROUND 60-------------------------------\n",
      "12 12\n",
      "global acc: 0.9199 ----- loss: 1.567501425743103\n",
      "-------------------------------ROUND 61-------------------------------\n",
      "12 12\n",
      "global acc: 0.921 ----- loss: 1.5667376518249512\n",
      "-------------------------------ROUND 62-------------------------------\n",
      "12 12\n",
      "global acc: 0.9213 ----- loss: 1.5668253898620605\n",
      "-------------------------------ROUND 63-------------------------------\n",
      "12 12\n",
      "global acc: 0.9216 ----- loss: 1.566601276397705\n",
      "-------------------------------ROUND 64-------------------------------\n",
      "12 12\n",
      "global acc: 0.9219 ----- loss: 1.566207766532898\n",
      "-------------------------------ROUND 65-------------------------------\n",
      "12 12\n",
      "global acc: 0.922 ----- loss: 1.5654960870742798\n",
      "-------------------------------ROUND 66-------------------------------\n",
      "12 12\n",
      "global acc: 0.9215 ----- loss: 1.565366506576538\n",
      "-------------------------------ROUND 67-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n",
      "global acc: 0.922 ----- loss: 1.565306544303894\n",
      "-------------------------------ROUND 68-------------------------------\n",
      "12 12\n",
      "global acc: 0.9214 ----- loss: 1.5647168159484863\n",
      "-------------------------------ROUND 69-------------------------------\n",
      "12 12\n",
      "global acc: 0.9232 ----- loss: 1.5647529363632202\n",
      "-------------------------------ROUND 70-------------------------------\n",
      "12 12\n",
      "global acc: 0.9218 ----- loss: 1.564865231513977\n",
      "-------------------------------ROUND 71-------------------------------\n",
      "12 12\n",
      "global acc: 0.9225 ----- loss: 1.564008355140686\n",
      "-------------------------------ROUND 72-------------------------------\n",
      "12 12\n",
      "global acc: 0.923 ----- loss: 1.5628762245178223\n",
      "-------------------------------ROUND 73-------------------------------\n",
      "12 12\n",
      "global acc: 0.9231 ----- loss: 1.5637736320495605\n",
      "-------------------------------ROUND 74-------------------------------\n",
      "12 12\n",
      "global acc: 0.9228 ----- loss: 1.5627269744873047\n",
      "-------------------------------ROUND 75-------------------------------\n",
      "12 12\n",
      "global acc: 0.9231 ----- loss: 1.562978744506836\n",
      "-------------------------------ROUND 76-------------------------------\n",
      "12 12\n",
      "global acc: 0.923 ----- loss: 1.56181800365448\n",
      "-------------------------------ROUND 77-------------------------------\n",
      "12 12\n",
      "global acc: 0.9239 ----- loss: 1.5622193813323975\n",
      "-------------------------------ROUND 78-------------------------------\n",
      "12 12\n",
      "global acc: 0.9235 ----- loss: 1.5617564916610718\n",
      "-------------------------------ROUND 79-------------------------------\n",
      "12 12\n",
      "global acc: 0.9224 ----- loss: 1.5623183250427246\n",
      "-------------------------------ROUND 80-------------------------------\n",
      "12 12\n",
      "global acc: 0.9238 ----- loss: 1.5624302625656128\n",
      "-------------------------------ROUND 81-------------------------------\n",
      "12 12\n",
      "global acc: 0.9237 ----- loss: 1.5606331825256348\n",
      "-------------------------------ROUND 82-------------------------------\n",
      "12 12\n",
      "global acc: 0.9233 ----- loss: 1.5605922937393188\n",
      "-------------------------------ROUND 83-------------------------------\n",
      "12 12\n",
      "global acc: 0.9242 ----- loss: 1.5607810020446777\n",
      "-------------------------------ROUND 84-------------------------------\n",
      "12 12\n",
      "global acc: 0.9221 ----- loss: 1.5605437755584717\n",
      "-------------------------------ROUND 85-------------------------------\n",
      "12 12\n",
      "global acc: 0.9235 ----- loss: 1.5600157976150513\n",
      "-------------------------------ROUND 86-------------------------------\n",
      "12 12\n",
      "global acc: 0.9242 ----- loss: 1.559543490409851\n",
      "-------------------------------ROUND 87-------------------------------\n",
      "12 12\n",
      "global acc: 0.925 ----- loss: 1.5598039627075195\n",
      "-------------------------------ROUND 88-------------------------------\n",
      "12 12\n",
      "global acc: 0.9249 ----- loss: 1.5590726137161255\n",
      "-------------------------------ROUND 89-------------------------------\n",
      "12 12\n",
      "global acc: 0.9248 ----- loss: 1.5590423345565796\n",
      "-------------------------------ROUND 90-------------------------------\n",
      "12 12\n",
      "global acc: 0.9248 ----- loss: 1.5587090253829956\n",
      "-------------------------------ROUND 91-------------------------------\n",
      "12 12\n",
      "global acc: 0.9245 ----- loss: 1.5582609176635742\n",
      "-------------------------------ROUND 92-------------------------------\n",
      "12 12\n",
      "global acc: 0.9246 ----- loss: 1.5585426092147827\n",
      "-------------------------------ROUND 93-------------------------------\n",
      "12 12\n",
      "global acc: 0.9243 ----- loss: 1.5581523180007935\n",
      "-------------------------------ROUND 94-------------------------------\n",
      "12 12\n",
      "global acc: 0.9248 ----- loss: 1.5576417446136475\n",
      "-------------------------------ROUND 95-------------------------------\n",
      "12 12\n",
      "global acc: 0.925 ----- loss: 1.5579107999801636\n",
      "-------------------------------ROUND 96-------------------------------\n",
      "12 12\n",
      "global acc: 0.9261 ----- loss: 1.5574575662612915\n",
      "-------------------------------ROUND 97-------------------------------\n",
      "12 12\n",
      "global acc: 0.9258 ----- loss: 1.5578198432922363\n",
      "-------------------------------ROUND 98-------------------------------\n",
      "12 12\n",
      "global acc: 0.9261 ----- loss: 1.5569744110107422\n",
      "-------------------------------ROUND 99-------------------------------\n",
      "12 12\n",
      "global acc: 0.926 ----- loss: 1.5572798252105713\n",
      "-------------------------------ROUND 100-------------------------------\n",
      "12 12\n",
      "global acc: 0.9265 ----- loss: 1.556772232055664\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "server = None\n",
    "server = Server()\n",
    "init_weights = server.model.get_weights()\n",
    "\n",
    "# Populate the server's client list with clients holding data\n",
    "server.clients = [Client(Dataset(train_data[i], train_data_labels[i], test_data[i], test_data_labels[i]), init_weights) for i in range(NUMBER_OF_CLIENTS)]\n",
    "server.federated_averaging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f63f854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------ROUND 1-------------------------------\n",
      "12 0\n",
      "global acc: 0.071 ----- loss: 2.3026318550109863\n",
      "-------------------------------ROUND 2-------------------------------\n",
      "12 12\n",
      "global acc: 0.1058 ----- loss: 2.302527666091919\n",
      "-------------------------------ROUND 3-------------------------------\n",
      "12 12\n",
      "global acc: 0.1159 ----- loss: 2.3023200035095215\n",
      "-------------------------------ROUND 4-------------------------------\n",
      "12 12\n",
      "global acc: 0.172 ----- loss: 2.294235944747925\n",
      "-------------------------------ROUND 5-------------------------------\n",
      "12 12\n",
      "global acc: 0.237 ----- loss: 2.269451856613159\n",
      "-------------------------------ROUND 6-------------------------------\n",
      "12 12\n",
      "global acc: 0.2841 ----- loss: 2.243104934692383\n",
      "-------------------------------ROUND 7-------------------------------\n",
      "12 12\n",
      "global acc: 0.3188 ----- loss: 2.2181649208068848\n",
      "-------------------------------ROUND 8-------------------------------\n",
      "12 12\n",
      "global acc: 0.3415 ----- loss: 2.203948736190796\n",
      "-------------------------------ROUND 9-------------------------------\n",
      "12 12\n",
      "global acc: 0.3636 ----- loss: 2.1823136806488037\n",
      "-------------------------------ROUND 10-------------------------------\n",
      "12 12\n",
      "global acc: 0.3898 ----- loss: 2.172734260559082\n",
      "-------------------------------ROUND 11-------------------------------\n",
      "12 12\n",
      "global acc: 0.4055 ----- loss: 2.1528801918029785\n",
      "-------------------------------ROUND 12-------------------------------\n",
      "12 12\n",
      "global acc: 0.4147 ----- loss: 2.142918825149536\n",
      "-------------------------------ROUND 13-------------------------------\n",
      "12 12\n",
      "global acc: 0.4291 ----- loss: 2.132469892501831\n",
      "-------------------------------ROUND 14-------------------------------\n",
      "12 12\n",
      "global acc: 0.4278 ----- loss: 2.1298608779907227\n",
      "-------------------------------ROUND 15-------------------------------\n",
      "12 12\n",
      "global acc: 0.4396 ----- loss: 2.1246109008789062\n",
      "-------------------------------ROUND 16-------------------------------\n",
      "12 12\n",
      "global acc: 0.452 ----- loss: 2.1088221073150635\n",
      "-------------------------------ROUND 17-------------------------------\n",
      "12 12\n",
      "global acc: 0.4499 ----- loss: 2.106863498687744\n",
      "-------------------------------ROUND 18-------------------------------\n",
      "12 12\n",
      "global acc: 0.4624 ----- loss: 2.0934343338012695\n",
      "-------------------------------ROUND 19-------------------------------\n",
      "12 12\n",
      "global acc: 0.4631 ----- loss: 2.0832583904266357\n",
      "-------------------------------ROUND 20-------------------------------\n",
      "12 12\n",
      "global acc: 0.4659 ----- loss: 2.0873024463653564\n",
      "-------------------------------ROUND 21-------------------------------\n",
      "12 12\n",
      "global acc: 0.4846 ----- loss: 2.079749584197998\n",
      "-------------------------------ROUND 22-------------------------------\n",
      "12 12\n",
      "global acc: 0.4856 ----- loss: 2.067312002182007\n",
      "-------------------------------ROUND 23-------------------------------\n",
      "12 12\n",
      "global acc: 0.4944 ----- loss: 2.0676393508911133\n",
      "-------------------------------ROUND 24-------------------------------\n",
      "12 12\n",
      "global acc: 0.4988 ----- loss: 2.058091640472412\n",
      "-------------------------------ROUND 25-------------------------------\n",
      "12 12\n",
      "global acc: 0.503 ----- loss: 2.058255195617676\n",
      "-------------------------------ROUND 26-------------------------------\n",
      "12 12\n",
      "global acc: 0.5095 ----- loss: 2.0518603324890137\n",
      "-------------------------------ROUND 27-------------------------------\n",
      "12 12\n",
      "global acc: 0.5112 ----- loss: 2.043839454650879\n",
      "-------------------------------ROUND 28-------------------------------\n",
      "12 12\n",
      "global acc: 0.517 ----- loss: 2.043426275253296\n",
      "-------------------------------ROUND 29-------------------------------\n",
      "12 12\n",
      "global acc: 0.5213 ----- loss: 2.0348961353302\n",
      "-------------------------------ROUND 30-------------------------------\n",
      "12 12\n",
      "global acc: 0.5198 ----- loss: 2.0357511043548584\n",
      "-------------------------------ROUND 31-------------------------------\n",
      "12 12\n",
      "global acc: 0.5312 ----- loss: 2.030371904373169\n",
      "-------------------------------ROUND 32-------------------------------\n",
      "12 12\n",
      "global acc: 0.5308 ----- loss: 2.026320219039917\n",
      "-------------------------------ROUND 33-------------------------------\n",
      "12 12\n",
      "global acc: 0.53 ----- loss: 2.0195226669311523\n",
      "-------------------------------ROUND 34-------------------------------\n",
      "12 12\n",
      "global acc: 0.5356 ----- loss: 2.01533579826355\n",
      "-------------------------------ROUND 35-------------------------------\n",
      "12 12\n",
      "global acc: 0.5425 ----- loss: 2.0162298679351807\n",
      "-------------------------------ROUND 36-------------------------------\n",
      "12 12\n",
      "global acc: 0.5394 ----- loss: 2.01235294342041\n",
      "-------------------------------ROUND 37-------------------------------\n",
      "12 12\n",
      "global acc: 0.5454 ----- loss: 2.0051631927490234\n",
      "-------------------------------ROUND 38-------------------------------\n",
      "12 12\n",
      "global acc: 0.5486 ----- loss: 2.004997730255127\n",
      "-------------------------------ROUND 39-------------------------------\n",
      "12 12\n",
      "global acc: 0.5477 ----- loss: 1.998245358467102\n",
      "-------------------------------ROUND 40-------------------------------\n",
      "12 12\n",
      "global acc: 0.5475 ----- loss: 2.0028364658355713\n",
      "-------------------------------ROUND 41-------------------------------\n",
      "12 12\n",
      "global acc: 0.5524 ----- loss: 1.9977210760116577\n",
      "-------------------------------ROUND 42-------------------------------\n",
      "12 12\n",
      "global acc: 0.5558 ----- loss: 1.9949142932891846\n",
      "-------------------------------ROUND 43-------------------------------\n",
      "12 12\n",
      "global acc: 0.5575 ----- loss: 1.9925707578659058\n",
      "-------------------------------ROUND 44-------------------------------\n",
      "12 12\n",
      "global acc: 0.5594 ----- loss: 1.9893386363983154\n",
      "-------------------------------ROUND 45-------------------------------\n",
      "12 12\n",
      "global acc: 0.5569 ----- loss: 1.9857527017593384\n",
      "-------------------------------ROUND 46-------------------------------\n",
      "12 12\n",
      "global acc: 0.5624 ----- loss: 1.9818464517593384\n",
      "-------------------------------ROUND 47-------------------------------\n",
      "12 12\n",
      "global acc: 0.5641 ----- loss: 1.9793777465820312\n",
      "-------------------------------ROUND 48-------------------------------\n",
      "12 12\n",
      "global acc: 0.5616 ----- loss: 1.985877513885498\n",
      "-------------------------------ROUND 49-------------------------------\n",
      "12 12\n",
      "global acc: 0.565 ----- loss: 1.9742945432662964\n",
      "-------------------------------ROUND 50-------------------------------\n",
      "12 12\n",
      "global acc: 0.5662 ----- loss: 1.9758864641189575\n",
      "-------------------------------ROUND 51-------------------------------\n",
      "12 12\n",
      "global acc: 0.5682 ----- loss: 1.973272681236267\n",
      "-------------------------------ROUND 52-------------------------------\n",
      "12 12\n",
      "global acc: 0.5627 ----- loss: 1.9749687910079956\n",
      "-------------------------------ROUND 53-------------------------------\n",
      "12 12\n",
      "global acc: 0.5706 ----- loss: 1.973513126373291\n",
      "-------------------------------ROUND 54-------------------------------\n",
      "12 12\n",
      "global acc: 0.5694 ----- loss: 1.9692434072494507\n",
      "-------------------------------ROUND 55-------------------------------\n",
      "12 12\n",
      "global acc: 0.568 ----- loss: 1.9710837602615356\n",
      "-------------------------------ROUND 56-------------------------------\n",
      "12 12\n",
      "global acc: 0.5705 ----- loss: 1.969558596611023\n",
      "-------------------------------ROUND 57-------------------------------\n",
      "12 12\n",
      "global acc: 0.5685 ----- loss: 1.9664171934127808\n",
      "-------------------------------ROUND 58-------------------------------\n",
      "12 12\n",
      "global acc: 0.5717 ----- loss: 1.9667187929153442\n",
      "-------------------------------ROUND 59-------------------------------\n",
      "12 12\n",
      "global acc: 0.5737 ----- loss: 1.9630472660064697\n",
      "-------------------------------ROUND 60-------------------------------\n",
      "12 12\n",
      "global acc: 0.5769 ----- loss: 1.9614830017089844\n",
      "-------------------------------ROUND 61-------------------------------\n",
      "12 12\n",
      "global acc: 0.5745 ----- loss: 1.9608429670333862\n",
      "-------------------------------ROUND 62-------------------------------\n",
      "12 12\n",
      "global acc: 0.5748 ----- loss: 1.9589987993240356\n",
      "-------------------------------ROUND 63-------------------------------\n",
      "12 12\n",
      "global acc: 0.5751 ----- loss: 1.9559296369552612\n",
      "-------------------------------ROUND 64-------------------------------\n",
      "12 12\n",
      "global acc: 0.5769 ----- loss: 1.9514847993850708\n",
      "-------------------------------ROUND 65-------------------------------\n",
      "12 12\n",
      "global acc: 0.5787 ----- loss: 1.9497476816177368\n",
      "-------------------------------ROUND 66-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n",
      "global acc: 0.5764 ----- loss: 1.9539241790771484\n",
      "-------------------------------ROUND 67-------------------------------\n",
      "12 12\n",
      "global acc: 0.5801 ----- loss: 1.953599452972412\n",
      "-------------------------------ROUND 68-------------------------------\n",
      "12 12\n",
      "global acc: 0.58 ----- loss: 1.9505667686462402\n",
      "-------------------------------ROUND 69-------------------------------\n",
      "12 12\n",
      "global acc: 0.5808 ----- loss: 1.9467500448226929\n",
      "-------------------------------ROUND 70-------------------------------\n",
      "12 12\n",
      "global acc: 0.5797 ----- loss: 1.9444458484649658\n",
      "-------------------------------ROUND 71-------------------------------\n",
      "12 12\n",
      "global acc: 0.5818 ----- loss: 1.9438023567199707\n",
      "-------------------------------ROUND 72-------------------------------\n",
      "12 12\n",
      "global acc: 0.5844 ----- loss: 1.9422539472579956\n",
      "-------------------------------ROUND 73-------------------------------\n",
      "12 12\n",
      "global acc: 0.5816 ----- loss: 1.9436421394348145\n",
      "-------------------------------ROUND 74-------------------------------\n",
      "12 12\n",
      "global acc: 0.5847 ----- loss: 1.9431167840957642\n",
      "-------------------------------ROUND 75-------------------------------\n",
      "12 12\n",
      "global acc: 0.5824 ----- loss: 1.9412208795547485\n",
      "-------------------------------ROUND 76-------------------------------\n",
      "12 12\n",
      "global acc: 0.5843 ----- loss: 1.941043734550476\n",
      "-------------------------------ROUND 77-------------------------------\n",
      "12 12\n",
      "global acc: 0.5819 ----- loss: 1.9413654804229736\n",
      "-------------------------------ROUND 78-------------------------------\n",
      "12 12\n",
      "global acc: 0.5839 ----- loss: 1.9380204677581787\n",
      "-------------------------------ROUND 79-------------------------------\n",
      "12 12\n",
      "global acc: 0.582 ----- loss: 1.9381134510040283\n",
      "-------------------------------ROUND 80-------------------------------\n",
      "12 12\n",
      "global acc: 0.5852 ----- loss: 1.9353834390640259\n",
      "-------------------------------ROUND 81-------------------------------\n",
      "12 12\n",
      "global acc: 0.5841 ----- loss: 1.935545563697815\n",
      "-------------------------------ROUND 82-------------------------------\n",
      "12 12\n",
      "global acc: 0.5843 ----- loss: 1.9319941997528076\n",
      "-------------------------------ROUND 83-------------------------------\n",
      "12 12\n",
      "global acc: 0.5854 ----- loss: 1.933689832687378\n",
      "-------------------------------ROUND 84-------------------------------\n",
      "12 12\n",
      "global acc: 0.5863 ----- loss: 1.9345718622207642\n",
      "-------------------------------ROUND 85-------------------------------\n",
      "12 12\n",
      "global acc: 0.5887 ----- loss: 1.929699182510376\n",
      "-------------------------------ROUND 86-------------------------------\n",
      "12 12\n",
      "global acc: 0.586 ----- loss: 1.9311091899871826\n",
      "-------------------------------ROUND 87-------------------------------\n",
      "12 12\n",
      "global acc: 0.5882 ----- loss: 1.9317023754119873\n",
      "-------------------------------ROUND 88-------------------------------\n",
      "12 12\n",
      "global acc: 0.586 ----- loss: 1.9313578605651855\n",
      "-------------------------------ROUND 89-------------------------------\n",
      "12 12\n",
      "global acc: 0.5856 ----- loss: 1.9274914264678955\n",
      "-------------------------------ROUND 90-------------------------------\n",
      "12 12\n",
      "global acc: 0.587 ----- loss: 1.9259765148162842\n",
      "-------------------------------ROUND 91-------------------------------\n",
      "12 12\n",
      "global acc: 0.5898 ----- loss: 1.9271843433380127\n",
      "-------------------------------ROUND 92-------------------------------\n",
      "12 12\n",
      "global acc: 0.5885 ----- loss: 1.928614854812622\n",
      "-------------------------------ROUND 93-------------------------------\n",
      "12 12\n",
      "global acc: 0.5881 ----- loss: 1.9248312711715698\n",
      "-------------------------------ROUND 94-------------------------------\n",
      "12 12\n",
      "global acc: 0.5893 ----- loss: 1.925051212310791\n",
      "-------------------------------ROUND 95-------------------------------\n",
      "12 12\n",
      "global acc: 0.5896 ----- loss: 1.9224636554718018\n",
      "-------------------------------ROUND 96-------------------------------\n",
      "12 12\n",
      "global acc: 0.5885 ----- loss: 1.9260914325714111\n",
      "-------------------------------ROUND 97-------------------------------\n",
      "12 12\n",
      "global acc: 0.59 ----- loss: 1.9218223094940186\n",
      "-------------------------------ROUND 98-------------------------------\n",
      "12 12\n",
      "global acc: 0.5886 ----- loss: 1.9208451509475708\n",
      "-------------------------------ROUND 99-------------------------------\n",
      "12 12\n",
      "global acc: 0.5861 ----- loss: 1.9201527833938599\n",
      "-------------------------------ROUND 100-------------------------------\n",
      "12 12\n",
      "global acc: 0.5886 ----- loss: 1.9184521436691284\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "#CIFAR10\n",
    "server1 = None\n",
    "server1 = Server()\n",
    "init_weights = server1.model.get_weights()\n",
    "\n",
    "# Populate the server's client list with clients holding data\n",
    "server1.clients = [Client(Dataset(cifar_train_data[i], cifar_train_data_labels[i], cifar_test_data[i], cifar_test_data_labels[i]), init_weights) for i in range(NUMBER_OF_CLIENTS)]\n",
    "server1.federated_averaging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73d452e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9397590361445783, 0.9167591564927858, 0.9191919191919192, 0.9211711711711712, 0.9138099902056807, 0.9226694915254238, 0.9412997903563941, 0.9408914728682171, 0.9242282507015903, 0.9442815249266863]\n",
      "[0.9388322520852641, 0.9123196448390677, 0.9173553719008265, 0.918918918918919, 0.910871694417238, 0.9258474576271186, 0.9371069182389937, 0.9437984496124031, 0.9251637043966323, 0.9423264907135875]\n",
      "[0.9360518999073216, 0.9167591564927858, 0.9136822773186409, 0.9211711711711712, 0.9020568070519099, 0.926906779661017, 0.9423480083857443, 0.938953488372093, 0.9223573433115061, 0.9393939393939394]\n"
     ]
    }
   ],
   "source": [
    "server.clients[0].local_results\n",
    "last_round_acc = [[], [], []]\n",
    "for i in server.clients:\n",
    "    last_round_acc[0].append(i.ensemble_results[0][-1])\n",
    "    last_round_acc[1].append(i.local_results[0][-1])\n",
    "    last_round_acc[2].append(i.global_results[0][-1])\n",
    "print(last_round_acc[0])\n",
    "print(last_round_acc[1])\n",
    "print(last_round_acc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a66e4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9519230769230769\n",
      "0.9509615384615384\n",
      "0.9509615384615384\n"
     ]
    }
   ],
   "source": [
    "server.clients[0].local_results\n",
    "last_round_acc = [[], [], []]\n",
    "for i in server.clients:\n",
    "    last_round_acc[0].append(i.ensemble_results[0][-1])\n",
    "    last_round_acc[1].append(i.local_results[0][-1])\n",
    "    last_round_acc[2].append(i.global_results[0][-1])\n",
    "print(last_round_acc[0][0])\n",
    "print(last_round_acc[1][0])\n",
    "print(last_round_acc[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa84d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.1864 - sparse_categorical_accuracy: 0.4853 - val_loss: 0.2668 - val_sparse_categorical_accuracy: 0.9104\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9272 - val_loss: 0.1787 - val_sparse_categorical_accuracy: 0.9422TA: 4s - loss: 0.2495 - s\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1737 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9502\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1477 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1500 - val_sparse_categorical_accuracy: 0.9503\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1399 - val_sparse_categorical_accuracy: 0.9558\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.1331 - val_sparse_categorical_accuracy: 0.9581\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1398 - val_sparse_categorical_accuracy: 0.9564\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1223 - val_sparse_categorical_accuracy: 0.9599\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.1275 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9730 - val_loss: 0.1204 - val_sparse_categorical_accuracy: 0.9640rical_a\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.1238 - val_sparse_categorical_accuracy: 0.9649\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9625tegorical_accuracy: 0.97\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9637\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9793 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1300 - val_sparse_categorical_accuracy: 0.9630\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9691\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.1288 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9623\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.1368 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0471 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.1382 - val_sparse_categorical_accuracy: 0.9641\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1340 - val_sparse_categorical_accuracy: 0.9649\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0336 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.1402 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.1358 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0276 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.1529 - val_sparse_categorical_accuracy: 0.9652\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9664\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.1586 - val_sparse_categorical_accuracy: 0.9654\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.1512 - val_sparse_categorical_accuracy: 0.9676\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0177 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.1614 - val_sparse_categorical_accuracy: 0.9661\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.1673 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0152 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.1665 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.1699 - val_sparse_categorical_accuracy: 0.9682\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.1689 - val_sparse_categorical_accuracy: 0.9681\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.1893 - val_sparse_categorical_accuracy: 0.9631\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.1800 - val_sparse_categorical_accuracy: 0.9677\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.1822 - val_sparse_categorical_accuracy: 0.9671\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.1938 - val_sparse_categorical_accuracy: 0.9653\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.1895 - val_sparse_categorical_accuracy: 0.9672\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.1922 - val_sparse_categorical_accuracy: 0.9660\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.1978 - val_sparse_categorical_accuracy: 0.9666\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.2038 - val_sparse_categorical_accuracy: 0.9676\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.2038 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.2068 - val_sparse_categorical_accuracy: 0.9655\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9659\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9989 - val_loss: 0.2119 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.2132 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.2143 - val_sparse_categorical_accuracy: 0.9677\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2203 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2259 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2269 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.2328 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9678\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2351 - val_sparse_categorical_accuracy: 0.9674\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2392 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2398 - val_sparse_categorical_accuracy: 0.9674\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2422 - val_sparse_categorical_accuracy: 0.9676\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2452 - val_sparse_categorical_accuracy: 0.9666\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2445 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2485 - val_sparse_categorical_accuracy: 0.9659\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2495 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2495 - val_sparse_categorical_accuracy: 0.9676\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2498 - val_sparse_categorical_accuracy: 0.9674\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2521 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2553 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2558 - val_sparse_categorical_accuracy: 0.9671\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2564 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2587 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2599 - val_sparse_categorical_accuracy: 0.9673\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0011 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2609 - val_sparse_categorical_accuracy: 0.9671\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0010 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2627 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0010 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2629 - val_sparse_categorical_accuracy: 0.9666\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 9.7254e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2638 - val_sparse_categorical_accuracy: 0.9673\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 9.3884e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2651 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 8.9972e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2671 - val_sparse_categorical_accuracy: 0.9671\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 8.9294e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2668 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 8.7845e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2683 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 9.0417e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2681 - val_sparse_categorical_accuracy: 0.9671\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 8.2729e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2690 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 8.2842e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2710 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 8.0382e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2693 - val_sparse_categorical_accuracy: 0.9673\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.9343e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2723 - val_sparse_categorical_accuracy: 0.9668\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.5545e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2721 - val_sparse_categorical_accuracy: 0.9673\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.6181e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2737 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.2147e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2736 - val_sparse_categorical_accuracy: 0.9673\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.2716e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2753 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.0661e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2763 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.9499e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2767 - val_sparse_categorical_accuracy: 0.9666\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 7.0489e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2770 - val_sparse_categorical_accuracy: 0.9664\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.7641e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2795 - val_sparse_categorical_accuracy: 0.9664\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.7326e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2790 - val_sparse_categorical_accuracy: 0.9666tegorical_\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.3822e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.3237e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2798 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.3119e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2816 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.1416e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2813 - val_sparse_categorical_accuracy: 0.9666\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 6.0663e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2821 - val_sparse_categorical_accuracy: 0.9672\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 5.6846e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2833 - val_sparse_categorical_accuracy: 0.9669\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 5.8109e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2830 - val_sparse_categorical_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.Dense(MNIST_CLASS_AMOUNT, activation='softmax')\n",
    "        ])\n",
    "model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=model_metrics\n",
    "             )\n",
    "hist = model.fit(\n",
    "                train_images.reshape(-1, 28, 28, 1), \n",
    "                train_labels, \n",
    "                epochs=100, \n",
    "                validation_data=(\n",
    "                    test_images.reshape(-1, 28, 28, 1),\n",
    "                    test_labels\n",
    "                ), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8906e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1417a0a6bb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['val_sparse_categorical_accuracy'], label='Accuracy - Centralized')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8,1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c59ef78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28a096ca1f0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnumber = 0\n",
    "c = server.clients\n",
    "local_preds = c[cnumber].local_pred()\n",
    "global_preds = c[cnumber].global_pred()\n",
    "combined_preds = []\n",
    "        \n",
    "local_dict = metrics.classification_report(c[cnumber].dataset.testing_labels, [np.argmax(p) for p in local_preds], output_dict=True)\n",
    "global_dict = metrics.classification_report(c[cnumber].dataset.testing_labels, [np.argmax(p) for p in global_preds], output_dict=True)\n",
    "        \n",
    "for i in range(len(local_preds)):\n",
    "    if np.argmax(local_preds[i]) == np.argmax(global_preds[i]):\n",
    "        combined_preds.append(local_preds[i])\n",
    "    elif local_dict[str(np.argmax(local_preds[i]))]['f1-score'] > global_dict[str(np.argmax(global_preds[i]))]['f1-score']:\n",
    "        combined_preds.append(local_preds[i])\n",
    "    else:\n",
    "        combined_preds.append(global_preds[i])\n",
    "\n",
    "#self.ensemble_results.append(metrics.classification_report(self.dataset.testing_labels, combined_preds, output_dict=True, digits=4))\n",
    "#res = self.calculate_metrics(combined_preds)\n",
    "\n",
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(c[cnumber].dataset.testing_labels, tf.argmax(combined_preds, axis=1))\n",
    "cmd = metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "cmd.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58daf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnumber = 2\n",
    "local_preds = server1.clients[cnumber].local_pred()\n",
    "global_preds = server1.clients[cnumber].global_pred()\n",
    "combined_preds = []\n",
    "        \n",
    "local_dict = metrics.classification_report(server1.clients[cnumber].dataset.testing_labels, [np.argmax(p) for p in local_preds], output_dict=True)\n",
    "global_dict = metrics.classification_report(server1.clients[cnumber].dataset.testing_labels, [np.argmax(p) for p in global_preds], output_dict=True)\n",
    "        \n",
    "for i in range(len(local_preds)):\n",
    "    if np.argmax(local_preds[i]) == np.argmax(global_preds[i]):\n",
    "        combined_preds.append(local_preds[i])\n",
    "    elif local_dict[str(np.argmax(local_preds[i]))]['f1-score'] > global_dict[str(np.argmax(global_preds[i]))]['f1-score']:\n",
    "        combined_preds.append(local_preds[i])\n",
    "    elif local_dict[str(np.argmax(local_preds[i]))]['f1-score'] < global_dict[str(np.argmax(global_preds[i]))]['f1-score']:\n",
    "        combined_preds.append(global_preds[i])\n",
    "    else:\n",
    "        combined_preds.append(global_preds[i])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33a030be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       350\n",
      "           1       0.96      0.99      0.98       104\n",
      "           2       0.95      0.96      0.95        74\n",
      "           3       0.89      0.92      0.91        92\n",
      "           4       0.94      0.80      0.87        76\n",
      "           5       0.97      0.87      0.92        75\n",
      "           6       0.96      0.95      0.96        80\n",
      "           7       0.90      0.93      0.91        80\n",
      "           8       0.90      0.87      0.88        70\n",
      "           9       0.84      0.91      0.87        78\n",
      "\n",
      "    accuracy                           0.94      1079\n",
      "   macro avg       0.93      0.92      0.92      1079\n",
      "weighted avg       0.94      0.94      0.94      1079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(c[cnumber].dataset.testing_labels, tf.argmax(combined_preds, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76c29792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28a09569e20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = len(server.clients[0].local_weights)\n",
    "avg_weights = []\n",
    "local_scaling_factor  = server.clients[0].get_sample_amount() / server.get_total_samples()\n",
    "global_scaling_factor = 1 - local_scaling_factor\n",
    "for i in range(size):\n",
    "    avg_weights.append(server.clients[0].local_weights[i] * local_scaling_factor + server.clients[0].global_weights[i] * global_scaling_factor)\n",
    "\n",
    "server.clients[0].model.set_weights(avg_weights)\n",
    "prediction = server.clients[0].model(server.clients[0].dataset.testing_data, training=False)\n",
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(server.clients[0].dataset.testing_labels, tf.argmax(prediction, axis=1))\n",
    "cmd = metrics.ConfusionMatrixDisplay(cm, display_labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "cmd.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d6c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
