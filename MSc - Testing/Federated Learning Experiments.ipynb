{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd00a72",
   "metadata": {},
   "source": [
    "# Federated learning - Client aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48529658",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6af8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205ae09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS\n",
    "NUMBER_OF_CLIENTS = 10 # Currently only 10 data splits\n",
    "LOCAL_EPOCHS = 3\n",
    "ROUNDS = 1\n",
    "LOCAL_LR = 0.01\n",
    "GLOBAL_LR = 0.1\n",
    "\n",
    "\n",
    "## FT CONSTANTS\n",
    "FT_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d9ba7",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b95fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lists(list_a, list_b, data_entry, data_label):\n",
    "    list_a[data_label].append(data_entry)\n",
    "    list_b[data_label].append(data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8b072",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f502ac",
   "metadata": {},
   "source": [
    "##### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13b9e45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m a,b:sort_lists(train_data,train_data_labels, a, b), train_images, train_labels))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#list(map(lambda a,b:sort_lists(test_data,test_data_labels, a, b), test_images, test_labels))\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m test_data, test_data_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43msplit\u001b[49m(test_images, NUMBER_OF_CLIENTS)), \u001b[38;5;28mlist\u001b[39m(split(test_labels, NUMBER_OF_CLIENTS))\n\u001b[0;32m      8\u001b[0m train_data, train_data_labels, test_data_labels, test_data_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(train_data), np\u001b[38;5;241m.\u001b[39masarray(train_data_labels), np\u001b[38;5;241m.\u001b[39masarray(test_data_labels), np\u001b[38;5;241m.\u001b[39masarray(test_data_labels)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(train_data_labels[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(test_data[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(test_data_labels[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split' is not defined"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "train_data, train_data_labels, test_data, test_data_labels = [[[] for i in range(10)] for i in range(4)]\n",
    "    \n",
    "list(map(lambda a,b:sort_lists(train_data,train_data_labels, a, b), train_images, train_labels))\n",
    "#list(map(lambda a,b:sort_lists(test_data,test_data_labels, a, b), test_images, test_labels))\n",
    "test_data, test_data_labels = list(split(test_images, NUMBER_OF_CLIENTS)), list(split(test_labels, NUMBER_OF_CLIENTS))\n",
    "\n",
    "train_data, train_data_labels, test_data_labels, test_data_labels = np.asarray(train_data), np.asarray(train_data_labels), np.asarray(test_data_labels), np.asarray(test_data_labels)\n",
    "\n",
    "print(len(train_data[0]), len(train_data_labels[0]), len(test_data[0]), len(test_data_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0422b37",
   "metadata": {},
   "source": [
    "###### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2f867cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cifar_images, cifar_labels), (cifar_test_images, cifar_test_labels) = datasets.cifar10.load_data()\n",
    "cifar_train_data, cifar_train_labels, cifar_test_data, cifar_test_labels = [[[] for i in range(10)] for i in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713ba2d",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd1658",
   "metadata": {},
   "source": [
    "###### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b37001b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "mnist_model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d4f93",
   "metadata": {},
   "source": [
    "###### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b1098a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1616c",
   "metadata": {},
   "source": [
    "### Classes and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d227a6",
   "metadata": {},
   "source": [
    "###### Server class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1e86f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self, model):\n",
    "        self.clients = []\n",
    "        self.client_weights = []\n",
    "        self.weights = []\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        self.model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(0.1),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    # Performs a single round of training for set amount of epochs    \n",
    "    def train_clients(self):\n",
    "        for c in self.clients:\n",
    "            self.client_weights.append(c.train())\n",
    "        return self.client_weights\n",
    "    \n",
    "    # Updates weights for server and clients\n",
    "    def update_weights(self, new_weights):\n",
    "        self.weights = new_weights\n",
    "        for c in self.clients:\n",
    "            c.update_weights(self.get_weights())\n",
    "            \n",
    "    # Performs federated averaging for given amount of rounds\n",
    "    def federated_averaging(self, rnds):\n",
    "        average_weights = np.asarray(self.model.get_weights())\n",
    "        # Training for a specified amount of rounds\n",
    "        for rnd in range(rnds):\n",
    "            t_weights = []\n",
    "            total_samples = 0\n",
    "            # Training loop - trains each client for a single round for a specified amount of epochs\n",
    "            for client in self.clients:\n",
    "                t_weights.append(client.train(LOCAL_EPOCHS))\n",
    "\n",
    "                total_samples += client.get_sample_amount()\n",
    "\n",
    "            tmp_weights = [t_weights[i] * len(self.clients[i].dataset.testing_data) for i in range(len(self.clients))]\n",
    "            tmp_weights = [w / total_samples for w in average_weights]\n",
    "\n",
    "            average_weights = [x + y for x, y in zip(init_weights, tmp_weights)]\n",
    "\n",
    "        self.update_weights(np.asarray(average_weights))\n",
    "        print('FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e491687",
   "metadata": {},
   "source": [
    "###### Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "583c941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing the client and the necessary methods a client requires.\n",
    "class Client():\n",
    "    def __init__(self, dataset):\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        self.model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(LOCAL_LR),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )\n",
    "        self.dataset = dataset\n",
    "        self.active_weights = self.get_weights()\n",
    "        self.rep_weights = self.active_weights\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    # Getter just for better readability\n",
    "    def get_sample_amount(self):\n",
    "        return len(self.dataset.training_data)\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        self.model.fit(\n",
    "                self.dataset.training_data, \n",
    "                self.dataset.training_labels, \n",
    "                epochs=LOCAL_EPOCHS, \n",
    "                validation_data=(\n",
    "                    self.dataset.testing_data,\n",
    "                    self.dataset.testing_labels\n",
    "                ))\n",
    "        \n",
    "        self.rep_weights = np.asarray(self.model.get_weights())\n",
    "        return self.rep_weights\n",
    "    \n",
    "    def update_weights(self, new_weights):\n",
    "        assert self.active_weights.shape == new_weights.shape, \"Shapes for the input weights are not the same\"\n",
    "        self.active_weights = np.mean( np.array([ self.active_weights, new_weights ]), axis=0 )\n",
    "        self.model.set_weights(self.active_weights)\n",
    "        \n",
    "    def fine_tune(self, new_weights):\n",
    "        pretrained_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        pretrained_model.set_weights(new_weights)\n",
    "        pretrained_model.trainable = True\n",
    "        fine_tune_at = int(len(pretrained_model.layers) / 3)\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "        pretrained_model.compile(optimizer=tf.keras.optimizers.SGD(LOCAL_LR/10),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )\n",
    "        \n",
    "        # train layers\n",
    "        ft_history = pretrained.model.fit(\n",
    "                                self.dataset.training_data,\n",
    "                                self.dataset.training_labels,\n",
    "                                epochs = LOCAL_EPOCHS + FT_EPOCHS,\n",
    "                                validation_data=(\n",
    "                                    self.dataset.testing_data,\n",
    "                                    self.dataset.testing_labels\n",
    "                                ))\n",
    "        return ft_history\n",
    "    \n",
    "    def ensemble(self):\n",
    "        for i, j in self.dataset.testing_data, self.dataset.testing_labels:\n",
    "            # evaluate both models on each datapoint, keep both results for now.\n",
    "        self.model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd18474",
   "metadata": {},
   "source": [
    "###### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "88abb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, training_data, training_labels, testing_data, testing_labels):\n",
    "        self.training_data = np.asarray(training_data)\n",
    "        self.training_labels = np.asarray(training_labels)\n",
    "        self.testing_data = np.asarray(testing_data)\n",
    "        self.testing_labels = np.asarray(testing_labels)\n",
    "        \n",
    "    def get_training_data_distribution(self):\n",
    "        labels = np.unique(self.training_labels)\n",
    "        dist = {}\n",
    "        for i in labels:\n",
    "            dist[i] = np.where(self.training_labels == i)\n",
    "        return dist\n",
    "    \n",
    "    def get_testing_data_distribution(self):\n",
    "        labels = np.unique(self.testing_labels)\n",
    "        dist = {}\n",
    "        for i in labels:\n",
    "            dist[i] = np.where(self.testing_labels == i)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160a35a",
   "metadata": {},
   "source": [
    "###### Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9f27b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_client_weights(weights, clients):\n",
    "    for c in clients:\n",
    "        c.model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "32ee8fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7ef55234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(array, partitions):\n",
    "    k, m = divmod(len(array), partitions)\n",
    "    return (array[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1be089fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 (array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   2, 101, 191, 232,  72,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,  33, 175, 254, 239, 254, 116,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,  23, 121, 250, 189,  93,  89, 250,  78,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         59, 213, 244, 129,  12,  12, 208, 254,  74,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55,\n",
      "        216, 244, 105,   0,   3, 122, 250, 192,  51,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 223,\n",
      "        247,  88,   0,   0, 108, 254, 211,  42,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   8, 213, 254,\n",
      "        126,   0,   0,  93, 230, 239,  40,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   6, 164, 254, 135,\n",
      "          3,  12, 155, 252, 251,  59,   1,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 144, 254, 210,  36,\n",
      "        132, 203, 255, 254, 167,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  15, 226, 254, 229, 240,\n",
      "        254, 254, 254, 202,  82,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  11, 244, 254, 254, 254,\n",
      "        255, 254, 207,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  35, 249, 254, 254, 254,\n",
      "        254, 246,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 131, 141, 110, 193,\n",
      "        253,  69,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 254,\n",
      "        166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 247, 248,\n",
      "         46,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   2, 185, 254, 128,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 125, 254, 188,   2,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  36, 245, 210,   4,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0, 161, 254, 152,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,  91, 241,  88,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0]], dtype=uint8), 9)\n"
     ]
    }
   ],
   "source": [
    "def mix_data(train_list, test_list):\n",
    "    train_img, train_lbl, test_img, test_lbl = [[[] for i in range(10)] for i in range(4)]\n",
    "    train_data = []\n",
    "    for i in range(len(train_list[0])):\n",
    "        train_data.append((train_list[0][i], train_list[1][i]))\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "    print(len(train_data), train_data[0])\n",
    "mix_data((train_images, train_labels), (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f5b68",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28305b21",
   "metadata": {},
   "source": [
    "##### Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6301411",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server(mnist_model)\n",
    "init_weights = np.asarray(server.model.get_weights())\n",
    "\n",
    "# Populate the server's client list with clients holding data\n",
    "server.clients = [Client(Dataset(train_data[i], train_data_labels[i], test_data[i], test_data_labels[i])) for i in range(NUMBER_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5057221",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48526671",
   "metadata": {},
   "source": [
    "##### No client aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f55a397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 1.9901 - sparse_categorical_accuracy: 0.9946 - val_loss: 67436.7969 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 2/3\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 67436.7969 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 3/3\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 67436.7969 - val_sparse_categorical_accuracy: 0.0850\n",
      "Epoch 1/3\n",
      "211/211 [==============================] - 1s 2ms/step - loss: 0.9379 - sparse_categorical_accuracy: 0.9953 - val_loss: 24262.4336 - val_sparse_categorical_accuracy: 0.1080\n",
      "Epoch 2/3\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 24262.4336 - val_sparse_categorical_accuracy: 0.1080\n",
      "Epoch 3/3\n",
      "211/211 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 24262.4336 - val_sparse_categorical_accuracy: 0.1080\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 1.7200 - sparse_categorical_accuracy: 0.9948 - val_loss: 65064.9375 - val_sparse_categorical_accuracy: 0.0940\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 65064.9375 - val_sparse_categorical_accuracy: 0.0940\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 65064.9375 - val_sparse_categorical_accuracy: 0.0940\n",
      "Epoch 1/3\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9990 - val_loss: 6347.6646 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 2/3\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 6347.6646 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 3/3\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 6347.6646 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 1/3\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.8127 - sparse_categorical_accuracy: 0.9945 - val_loss: 47370.0547 - val_sparse_categorical_accuracy: 0.0820\n",
      "Epoch 2/3\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 47370.0547 - val_sparse_categorical_accuracy: 0.0820\n",
      "Epoch 3/3\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 47370.0547 - val_sparse_categorical_accuracy: 0.0820\n",
      "Epoch 1/3\n",
      "170/170 [==============================] - 1s 2ms/step - loss: 1.7408 - sparse_categorical_accuracy: 0.9941 - val_loss: 43571.0898 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 2/3\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 43571.0898 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 3/3\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 43571.0898 - val_sparse_categorical_accuracy: 0.0920\n",
      "Epoch 1/3\n",
      "185/185 [==============================] - 1s 2ms/step - loss: 2.0541 - sparse_categorical_accuracy: 0.9946 - val_loss: 46441.3555 - val_sparse_categorical_accuracy: 0.0940\n",
      "Epoch 2/3\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 46441.3555 - val_sparse_categorical_accuracy: 0.0940\n",
      "Epoch 3/3\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 46441.3555 - val_sparse_categorical_accuracy: 0.0940\n",
      "Epoch 1/3\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.8829 - sparse_categorical_accuracy: 0.9949 - val_loss: 71120.9531 - val_sparse_categorical_accuracy: 0.1010\n",
      "Epoch 2/3\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 71120.9531 - val_sparse_categorical_accuracy: 0.1010\n",
      "Epoch 3/3\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 71120.9531 - val_sparse_categorical_accuracy: 0.1010\n",
      "Epoch 1/3\n",
      "183/183 [==============================] - 1s 2ms/step - loss: 0.7573 - sparse_categorical_accuracy: 0.9945 - val_loss: 95015.3438 - val_sparse_categorical_accuracy: 0.0930\n",
      "Epoch 2/3\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 95015.3438 - val_sparse_categorical_accuracy: 0.0930\n",
      "Epoch 3/3\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 95015.3438 - val_sparse_categorical_accuracy: 0.0930\n",
      "Epoch 1/3\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 1.3819 - sparse_categorical_accuracy: 0.9946 - val_loss: 57038.9219 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 2/3\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 57038.9219 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 3/3\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 57038.9219 - val_sparse_categorical_accuracy: 0.0900\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "# Initialize the clients' weights\n",
    "set_client_weights(init_weights, server.clients)\n",
    "\n",
    "# Perform federated averaging on the clients\n",
    "server.federated_averaging(ROUNDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f401a7",
   "metadata": {},
   "source": [
    "##### Weighted averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd5c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46356cf2",
   "metadata": {},
   "source": [
    "##### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f854f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c06915",
   "metadata": {},
   "source": [
    "##### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/tutorials/images/transfer_learning#fine_tuning\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7454d2",
   "metadata": {},
   "source": [
    "# Testing - delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "48a03dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 65.9813 - sparse_categorical_accuracy: 0.0980\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 83.6496 - sparse_categorical_accuracy: 0.0750\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 59.3382 - sparse_categorical_accuracy: 0.0780\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 59.2997 - sparse_categorical_accuracy: 0.1630\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 73.3535 - sparse_categorical_accuracy: 0.0540\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 93.4958 - sparse_categorical_accuracy: 0.0970\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 74.3799 - sparse_categorical_accuracy: 0.0550\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 92.7069 - sparse_categorical_accuracy: 0.0850\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 85.0474 - sparse_categorical_accuracy: 0.0780\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 103.9552 - sparse_categorical_accuracy: 0.0970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[65.9813461303711, 0.09799999743700027],\n",
       " [83.64959716796875, 0.07500000298023224],\n",
       " [59.338199615478516, 0.07800000160932541],\n",
       " [59.299659729003906, 0.16300000250339508],\n",
       " [73.35354614257812, 0.05400000140070915],\n",
       " [93.49577331542969, 0.09700000286102295],\n",
       " [74.37986755371094, 0.054999999701976776],\n",
       " [92.70693969726562, 0.08500000089406967],\n",
       " [85.04742431640625, 0.07800000160932541],\n",
       " [103.95523071289062, 0.09700000286102295]]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate clients\n",
    "results = []\n",
    "for c in server.clients:\n",
    "    results.append(c.model.evaluate(c.dataset.testing_data, c.dataset.testing_labels, 128))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0b154f49",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_46452/3033198390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sparse_categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_sparse_categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plt.plot(server.model.history['sparse_categorical_accuracy'], label='accuracy')\n",
    "plt.plot(server.model.history['val_sparse_categorical_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(np.asarray(orderedListDataTest[0]),  np.asarray(orderedListLabelsTest[0]), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MODELS = 10\n",
    "models = []\n",
    "for i in range(NUMBER_OF_MODELS):\n",
    "    \n",
    "    models.append(\n",
    "        Client(model.fit(\n",
    "            np.asarray(orderedListData[i]), \n",
    "            np.asarray(orderedListLabels[i]), \n",
    "            epochs=10, \n",
    "            validation_data=(\n",
    "                np.asarray(orderedListDataTest[i]), np.asarray(orderedListLabelsTest[i])\n",
    "            )), len(orderedListData[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(models[0].model.get_weights() == models[1].model.get_weights()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(models[0].model.get_weights(), models[1].model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].sample_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bd4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2aa2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[] for i in range(10)]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9449f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_data[train_labels[i]].append(train_images[i]) for i in range(len(train_images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a146c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c4984cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = np.asarray(init_weights) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a3fe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32),\n",
       "       array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "      dtype=float32),\n",
       "       array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32),\n",
       "       array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_weights + np.asarray(init_weights)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55e3b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f085e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.02979872, -0.07496471,  0.06127212, ...,  0.00026497,\n",
       "         0.01988209,  0.02875005],\n",
       "       [-0.06187219, -0.07302045, -0.06389229, ..., -0.04385625,\n",
       "        -0.00143486,  0.0573824 ],\n",
       "       [-0.06367228, -0.03734235, -0.01923789, ..., -0.04568401,\n",
       "        -0.07224934, -0.05466868],\n",
       "       ...,\n",
       "       [ 0.06434707, -0.04622708, -0.01274758, ...,  0.0193691 ,\n",
       "         0.08004429,  0.04332334],\n",
       "       [ 0.0633579 ,  0.03055925, -0.06869059, ..., -0.06149226,\n",
       "         0.0326076 ,  0.06383979],\n",
       "       [-0.037656  , -0.00455572, -0.0554471 , ...,  0.03669924,\n",
       "        -0.02400378, -0.00825565]], dtype=float32),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "       array([[ 0.08472936, -0.06166583,  0.01433192, ..., -0.06677844,\n",
       "         0.09587781,  0.09025569],\n",
       "       [-0.20826639,  0.00981821,  0.1571999 , ..., -0.15568763,\n",
       "         0.09765811,  0.04251079],\n",
       "       [-0.04298088, -0.12317774,  0.10682292, ...,  0.10534553,\n",
       "        -0.20627004, -0.03356814],\n",
       "       ...,\n",
       "       [ 0.19805981,  0.1472976 ,  0.03135423, ..., -0.12425489,\n",
       "         0.11928274,  0.18753935],\n",
       "       [-0.05642343,  0.15463425, -0.12697399, ..., -0.19445358,\n",
       "        -0.13036117, -0.11739852],\n",
       "       [ 0.11140247,  0.2001471 , -0.05152532, ...,  0.14789365,\n",
       "         0.06700419,  0.0935718 ]], dtype=float32),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09ef4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "        150, 253, 202,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 190, 251,\n",
       "        251, 251, 253, 169, 109,  62,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251,\n",
       "        251, 251, 253, 251, 251, 220,  51,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 255, 253, 253,\n",
       "        253, 253, 234, 222, 253, 253, 253,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 221, 253, 251, 251,\n",
       "        251, 147,  77,  62, 128, 251, 251, 105,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 231, 251, 253, 251, 220,\n",
       "        137,  10,   0,   0,  31, 230, 251, 243, 113,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 188,  20,\n",
       "          0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 201,  30,   0,\n",
       "          0,   0,   0,   0,   0,  31, 200, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 253, 253,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  32, 202, 255, 253, 164,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0,  21,  63, 231, 251, 253, 230,  30,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0, 144, 251, 251, 251, 221,  61,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0, 182, 221, 251, 251, 251, 180,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 218, 253, 253,  73,  73, 228,\n",
       "        253, 253, 255, 253, 253, 253, 253,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 113, 251, 251, 253, 251, 251,\n",
       "        251, 251, 253, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  31, 230, 251, 253, 251, 251,\n",
       "        251, 251, 253, 230, 189,  35,  10,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  62, 142, 253, 251, 251,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 174, 251,\n",
       "        173,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84d521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
