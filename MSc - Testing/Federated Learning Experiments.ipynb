{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd00a72",
   "metadata": {},
   "source": [
    "# Federated learning - Client aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48529658",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6af8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8b072",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f502ac",
   "metadata": {},
   "source": [
    "##### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13b9e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923 5923 980 980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "train_data, train_data_labels, test_data, test_data_labels = [[[] for i in range(10)] for i in range(4)]\n",
    "    \n",
    "list(map(lambda a,b:sort_lists(train_data,train_data_labels, a, b), train_images, train_labels))\n",
    "list(map(lambda a,b:sort_lists(test_data,test_data_labels, a, b), test_images, test_labels))\n",
    "\n",
    "train_data, train_data_labels, test_data_labels, test_data_labels = np.asarray(train_data), np.asarray(train_data_labels), np.asarray(test_data_labels), np.asarray(test_data_labels)\n",
    "print(len(train_data[0]), len(train_data_labels[0]), len(test_data[0]), len(test_data_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0422b37",
   "metadata": {},
   "source": [
    "###### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f867cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cifar_images, cifar_labels), (cifar_test_images, cifar_test_labels) = datasets.cifar10.load_data()\n",
    "cifar_train_data, cifar_train_labels, cifar_test_data, cifar_test_labels = [[[] for i in range(10)] for i in range(4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713ba2d",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd1658",
   "metadata": {},
   "source": [
    "###### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37001b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "mnist_model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d4f93",
   "metadata": {},
   "source": [
    "###### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1098a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1616c",
   "metadata": {},
   "source": [
    "### Classes and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d227a6",
   "metadata": {},
   "source": [
    "###### Server class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e86f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server():\n",
    "    def __init__(self, model):\n",
    "        self.clients = []\n",
    "        self.client_weights = []\n",
    "        self.weights = []\n",
    "        self.model = model\n",
    "        self.model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(0.1),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    # Performs a single round of training for set amount of epochs    \n",
    "    def train_clients(self):\n",
    "        for c in self.clients:\n",
    "            self.client_weights.append(c.train())\n",
    "        return self.client_weights\n",
    "    \n",
    "    # Updates weights for server and clients\n",
    "    def update_weights(self, new_weights):\n",
    "        self.weights = new_weights\n",
    "        for c in self.clients:\n",
    "            client.update_weights(self.get_weights())\n",
    "            \n",
    "    # Performs federated averaging for given amount of rounds\n",
    "    def federated_averaging(self, rnds):\n",
    "        average_weights = np.asarray(self.model.get_weights())\n",
    "        # Training for a specified amount of rounds\n",
    "        for rnd in range(rnds):\n",
    "            t_weights = []\n",
    "            total_samples = 0\n",
    "            # Training loop - trains each client for a single round for a specified amount of epochs\n",
    "            for client in self.clients:\n",
    "                t_weights.append(client.train())\n",
    "\n",
    "                total_samples += client.get_sample_amount()\n",
    "\n",
    "            tmp_weights = [t_weights[i] * len(self.clients[i].dataset.testing_data) for i in range(len(self.clients))]\n",
    "            tmp_weights = [w / total_samples for w in average_weights]\n",
    "\n",
    "            average_weights = [x + y for x, y in zip(init_weights, tmp_weights)]\n",
    "\n",
    "        self.update_weights(average_weights)\n",
    "        print('FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e491687",
   "metadata": {},
   "source": [
    "###### Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583c941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing the client and the necessary methods a client requires.\n",
    "class Client():\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.active_weights = self.get_weights()\n",
    "        self.rep_weights = self.active_weights\n",
    "        \n",
    "    # Implementing a getter because TF get_weights returns a list rather than array.\n",
    "    def get_weights(self):\n",
    "        return np.asarray(self.model.get_weights())\n",
    "    \n",
    "    # Getter just for better readability\n",
    "    def get_sample_amount(self):\n",
    "        return len(self.dataset.training_data)\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        self.model.fit(\n",
    "                self.dataset.training_data, \n",
    "                self.dataset.training_labels, \n",
    "                epochs=LOCAL_EPOCHS, \n",
    "                validation_data=(\n",
    "                    self.dataset.testing_data,\n",
    "                    self.dataset.testing_labels\n",
    "                ))\n",
    "        \n",
    "        self.rep_weights = np.asarray(self.model.get_weights())\n",
    "        return self.rep_weights\n",
    "    \n",
    "    def update_weights(self, new_weights):\n",
    "        assert self.active_weights.shape == new_weights.shape, \"Shapes for the input weights are not the same\"\n",
    "        self.active_weights = np.mean( np.array([ self.active_weights, new_weights ]), axis=0 )\n",
    "        self.model.set_weights(self.active_weights)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd18474",
   "metadata": {},
   "source": [
    "###### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88abb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, training_data, training_labels, testing_data, testing_labels):\n",
    "        self.training_data = np.asarray(training_data)\n",
    "        self.training_labels = np.asarray(training_labels)\n",
    "        self.testing_data = np.asarray(testing_data)\n",
    "        self.testing_labels = np.asarray(testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160a35a",
   "metadata": {},
   "source": [
    "###### Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_client_weights(weights, clients):\n",
    "    for c in clients:\n",
    "        c.model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ee8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_lists(list_a, list_b, data_entry, data_label):\n",
    "    list_a[data_label].append(data_entry)\n",
    "    list_b[data_label].append(data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f5b68",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7067d8",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9112c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLIENTS = 10 # Currently only 10 data splits\n",
    "LOCAL_EPOCHS = 3\n",
    "ROUNDS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28305b21",
   "metadata": {},
   "source": [
    "##### Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6301411",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server(mnist_model)\n",
    "init_weights = np.asarray(server.model.get_weights())\n",
    "\n",
    "# Populate the server's client list with clients holding data\n",
    "server.clients = [Client(copy.deepcopy(mnist_model), Dataset(train_data[i], train_data_labels[i], test_data[i], test_data_labels[i])) for i in range(NUMBER_OF_CLIENTS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5057221",
   "metadata": {},
   "source": [
    "##### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the clients' weights\n",
    "set_client_weights(init_weights, server.clients)\n",
    "\n",
    "# Perform federated averaging on the clients\n",
    "server.federated_averaging(ROUNDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7454d2",
   "metadata": {},
   "source": [
    "# Testing - delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc0cb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "186/186 [==============================] - 11s 6ms/step - loss: 0.2625 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.1612 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "187/187 [==============================] - 1s 6ms/step - loss: 0.1646 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.2242 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.0702 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "170/170 [==============================] - 1s 5ms/step - loss: 0.1143 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "170/170 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "185/185 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "185/185 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.2066 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.1585 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 1/3\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "186/186 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'update_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21000/1493316789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FINISHED'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfederated_averaging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROUNDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21000/2540756577.py\u001b[0m in \u001b[0;36mfederated_averaging\u001b[1;34m(self, rnds)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0maverage_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FINISHED'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21000/2540756577.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[1;34m(self, new_weights)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfederated_averaging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'update_weights'"
     ]
    }
   ],
   "source": [
    "\n",
    "#model.set_weights(init_weights)\n",
    "def FedAvg():\n",
    "    weights = []\n",
    "    average_weights = np.asarray(model.get_weights())\n",
    "    # Training for a specified amount of rounds\n",
    "    for rnd in range(ROUNDS):\n",
    "        t_weights = []\n",
    "        total_samples = 0\n",
    "        # Training loop - trains each client for a single round for a specified amount of epochs\n",
    "        for client in clients:\n",
    "            t_weights.append(client.train())\n",
    "            \n",
    "            total_samples += client.get_sample_amount()\n",
    "            \n",
    "        tmp_weights = [t_weights[i] * len(clients[i].dataset.testing_data) for i in range(NUMBER_OF_CLIENTS)]\n",
    "        tmp_weights = [w / total_samples for w in average_weights]\n",
    "        \n",
    "        average_weights = [x + y for x, y in zip(init_weights, tmp_weights)]\n",
    "        \n",
    "    model.set_weights(average_weights)\n",
    "    print('FINISHED')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a03dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.06603812,  0.06138564,  0.01882748, ..., -0.0106024 ,\n",
       "         -0.04984839, -0.07946195],\n",
       "        [-0.05135015,  0.02872749, -0.05567926, ..., -0.02771584,\n",
       "          0.00838172,  0.03980216],\n",
       "        [ 0.04505598, -0.07869708, -0.04524029, ...,  0.04245869,\n",
       "         -0.03200928, -0.06609197],\n",
       "        ...,\n",
       "        [ 0.04489557,  0.06759686,  0.06125114, ...,  0.02124279,\n",
       "          0.03095571,  0.04465731],\n",
       "        [ 0.02795984,  0.03932033, -0.00414574, ...,  0.07700751,\n",
       "          0.05062222, -0.04201375],\n",
       "        [-0.04542928,  0.04772121, -0.01172901, ...,  0.02784236,\n",
       "         -0.07734098,  0.05741563]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.17414075, -0.09598271, -0.09438705, ..., -0.01488483,\n",
       "          0.10034315, -0.11763129],\n",
       "        [-0.00774544,  0.07380359,  0.07811685, ...,  0.13968872,\n",
       "         -0.1985648 , -0.13654706],\n",
       "        [-0.18698937, -0.19394118, -0.13486016, ..., -0.09017515,\n",
       "         -0.08909532, -0.11771217],\n",
       "        ...,\n",
       "        [ 0.10200994, -0.04126963,  0.12231357, ...,  0.10826652,\n",
       "          0.1373813 ,  0.06595995],\n",
       "        [-0.20071453, -0.1450219 ,  0.06255655, ...,  0.02044123,\n",
       "         -0.06301361, -0.1918473 ],\n",
       "        [-0.00610156,  0.0576001 , -0.08725233, ..., -0.0915134 ,\n",
       "         -0.1942073 ,  0.04392843]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedCD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "453dffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.9521 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    np.asarray(clients[0].dataset.training_data), \n",
    "    np.asarray(clients[0].dataset.training_labels), \n",
    "    epochs=10, \n",
    "    validation_data=(\n",
    "        np.asarray(clients[0].dataset.testing_data), \n",
    "        np.asarray(clients[0].dataset.testing_labels)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b154f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['sparse_categorical_accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(np.asarray(orderedListDataTest[0]),  np.asarray(orderedListLabelsTest[0]), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MODELS = 10\n",
    "models = []\n",
    "for i in range(NUMBER_OF_MODELS):\n",
    "    \n",
    "    models.append(\n",
    "        Client(model.fit(\n",
    "            np.asarray(orderedListData[i]), \n",
    "            np.asarray(orderedListLabels[i]), \n",
    "            epochs=10, \n",
    "            validation_data=(\n",
    "                np.asarray(orderedListDataTest[i]), np.asarray(orderedListLabelsTest[i])\n",
    "            )), len(orderedListData[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(models[0].model.get_weights() == models[1].model.get_weights()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(models[0].model.get_weights(), models[1].model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].sample_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bd4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2aa2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [[] for i in range(10)]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9449f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_data[train_labels[i]].append(train_images[i]) for i in range(len(train_images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a146c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c4984cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = np.asarray(init_weights) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4a3fe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\projects\\python sesong 2\\env\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32),\n",
       "       array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "      dtype=float32),\n",
       "       array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       ...,\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32),\n",
       "       array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_weights + np.asarray(init_weights)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55e3b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f085e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.02979872, -0.07496471,  0.06127212, ...,  0.00026497,\n",
       "         0.01988209,  0.02875005],\n",
       "       [-0.06187219, -0.07302045, -0.06389229, ..., -0.04385625,\n",
       "        -0.00143486,  0.0573824 ],\n",
       "       [-0.06367228, -0.03734235, -0.01923789, ..., -0.04568401,\n",
       "        -0.07224934, -0.05466868],\n",
       "       ...,\n",
       "       [ 0.06434707, -0.04622708, -0.01274758, ...,  0.0193691 ,\n",
       "         0.08004429,  0.04332334],\n",
       "       [ 0.0633579 ,  0.03055925, -0.06869059, ..., -0.06149226,\n",
       "         0.0326076 ,  0.06383979],\n",
       "       [-0.037656  , -0.00455572, -0.0554471 , ...,  0.03669924,\n",
       "        -0.02400378, -0.00825565]], dtype=float32),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "       array([[ 0.08472936, -0.06166583,  0.01433192, ..., -0.06677844,\n",
       "         0.09587781,  0.09025569],\n",
       "       [-0.20826639,  0.00981821,  0.1571999 , ..., -0.15568763,\n",
       "         0.09765811,  0.04251079],\n",
       "       [-0.04298088, -0.12317774,  0.10682292, ...,  0.10534553,\n",
       "        -0.20627004, -0.03356814],\n",
       "       ...,\n",
       "       [ 0.19805981,  0.1472976 ,  0.03135423, ..., -0.12425489,\n",
       "         0.11928274,  0.18753935],\n",
       "       [-0.05642343,  0.15463425, -0.12697399, ..., -0.19445358,\n",
       "        -0.13036117, -0.11739852],\n",
       "       [ 0.11140247,  0.2001471 , -0.05152532, ...,  0.14789365,\n",
       "         0.06700419,  0.0935718 ]], dtype=float32),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09ef4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "        150, 253, 202,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 190, 251,\n",
       "        251, 251, 253, 169, 109,  62,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251,\n",
       "        251, 251, 253, 251, 251, 220,  51,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 255, 253, 253,\n",
       "        253, 253, 234, 222, 253, 253, 253,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 221, 253, 251, 251,\n",
       "        251, 147,  77,  62, 128, 251, 251, 105,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 231, 251, 253, 251, 220,\n",
       "        137,  10,   0,   0,  31, 230, 251, 243, 113,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 188,  20,\n",
       "          0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 201,  30,   0,\n",
       "          0,   0,   0,   0,   0,  31, 200, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 253, 253,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  32, 202, 255, 253, 164,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0,  21,  63, 231, 251, 253, 230,  30,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0,   0, 144, 251, 251, 251, 221,  61,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,\n",
       "          0,   0, 182, 221, 251, 251, 251, 180,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 218, 253, 253,  73,  73, 228,\n",
       "        253, 253, 255, 253, 253, 253, 253,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 113, 251, 251, 253, 251, 251,\n",
       "        251, 251, 253, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  31, 230, 251, 253, 251, 251,\n",
       "        251, 251, 253, 230, 189,  35,  10,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  62, 142, 253, 251, 251,\n",
       "        251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 174, 251,\n",
       "        173,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84d521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
